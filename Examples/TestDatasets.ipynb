{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining MI_prediction from git+https://github.com/UN-GCPDS/python-gcpds.MI_prediction.git#egg=MI_prediction\n",
      "  Updating ./src/mi-prediction clone\n",
      "  Running command git fetch -q --tags\n",
      "  Running command git reset --hard -q 9a6aec113730ead0e9268be2e0faaa9c44fec5d9\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: moabb in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from MI_prediction) (0.4.6)\n",
      "Requirement already satisfied: braindecode in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from MI_prediction) (0.6)\n",
      "Requirement already satisfied: pandas in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (1.4.3)\n",
      "Requirement already satisfied: numpy in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (1.23.1)\n",
      "Requirement already satisfied: matplotlib in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (3.5.2)\n",
      "Requirement already satisfied: h5py in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (3.7.0)\n",
      "Requirement already satisfied: scipy in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (1.8.1)\n",
      "Requirement already satisfied: mne in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (1.0.3)\n",
      "Requirement already satisfied: skorch in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (0.11.0)\n",
      "Requirement already satisfied: pyriemann>=0.2.6 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (0.3)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.62 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (4.64.0)\n",
      "Requirement already satisfied: seaborn>=0.9 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (0.11.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.15.1 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (2.28.1)\n",
      "Requirement already satisfied: PyYAML<6.0,>=5.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (5.4.1)\n",
      "Requirement already satisfied: coverage<6.0,>=5.5 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (5.5)\n",
      "Requirement already satisfied: pooch<2.0,>=1.6 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (1.6.0)\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (4.34.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (3.0.9)\n",
      "Requirement already satisfied: decorator in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from mne->braindecode->MI_prediction) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from mne->braindecode->MI_prediction) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from pandas->braindecode->MI_prediction) (2022.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from pooch<2.0,>=1.6->moabb->MI_prediction) (1.4.4)\n",
      "Requirement already satisfied: joblib in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from pyriemann>=0.2.6->moabb->MI_prediction) (1.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from requests<3.0.0,>=2.15.1->moabb->MI_prediction) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from requests<3.0.0,>=2.15.1->moabb->MI_prediction) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from requests<3.0.0,>=2.15.1->moabb->MI_prediction) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from requests<3.0.0,>=2.15.1->moabb->MI_prediction) (2022.6.15)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from scikit-learn<2.0,>=1.0->moabb->MI_prediction) (3.1.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from skorch->braindecode->MI_prediction) (0.8.10)\n",
      "Requirement already satisfied: six>=1.5 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->braindecode->MI_prediction) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from jinja2->mne->braindecode->MI_prediction) (2.1.1)\n",
      "Installing collected packages: MI_prediction\n",
      "  Attempting uninstall: MI_prediction\n",
      "    Found existing installation: MI-prediction 0.1\n",
      "    Uninstalling MI-prediction-0.1:\n",
      "      Successfully uninstalled MI-prediction-0.1\n",
      "  Running setup.py develop for MI_prediction\n",
      "Successfully installed MI_prediction-0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install -U git+https://github.com/UN-GCPDS/python-gcpds.MI_prediction.git &> /dev/null\n",
    "%pip install -e git+https://github.com/UN-GCPDS/python-gcpds.MI_prediction.git#egg=MI_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MI_prediction.Utils.Datasets import DataLoader, get_epochs, get_runs\n",
    "from braindecode.preprocessing.preprocess import exponential_moving_standardize, preprocess, Preprocessor, scale\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCI IIa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset_name=\"BNCI2014001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A03T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A03T.mat'.\n",
      "100%|█████████████████████████████████████| 44.1M/44.1M [00:00<00:00, 20.2GB/s]\n",
      "SHA256 hash of downloaded file: 7e731ee8b681d5da6ecb11ae1d4e64b1653c7f15aad5d6b7620b25ce53141e80\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A03E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A03E.mat'.\n",
      "100%|█████████████████████████████████████| 42.3M/42.3M [00:00<00:00, 19.9GB/s]\n",
      "SHA256 hash of downloaded file: d4229267ec7624fa8bd3af5cbebac17f415f7c722de6cb676748f8cb3b717d97\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A04T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A04T.mat'.\n",
      "100%|█████████████████████████████████████| 37.2M/37.2M [00:00<00:00, 15.3GB/s]\n",
      "SHA256 hash of downloaded file: 15850d81b95fc88cc8b9589eb9b713d49fa071e28adaf32d675b3eaa30591d6e\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A04E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A04E.mat'.\n",
      "100%|█████████████████████████████████████| 41.7M/41.7M [00:00<00:00, 43.2GB/s]\n",
      "SHA256 hash of downloaded file: 81916dff2c12997974ba50ffc311da006ea66e525010d010765f0047e771c86a\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A05T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A05T.mat'.\n",
      "100%|█████████████████████████████████████| 42.5M/42.5M [00:00<00:00, 25.6GB/s]\n",
      "SHA256 hash of downloaded file: 77387d3b669f4ed9a7c1dac4dcba4c2c40c8910bae20fb961bb7cf5a94912950\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A05E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A05E.mat'.\n",
      "100%|█████████████████████████████████████| 44.4M/44.4M [00:00<00:00, 24.0GB/s]\n",
      "SHA256 hash of downloaded file: 8b357470865610c28b2f1d351beac247a56a856f02b2859d650736eb2ef77808\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A06T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A06T.mat'.\n",
      "100%|█████████████████████████████████████| 44.6M/44.6M [00:00<00:00, 15.8GB/s]\n",
      "SHA256 hash of downloaded file: 4dc3be1b0d60279134d1220323c73c68cf73799339a7fb224087a3c560a9a7e2\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A06E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A06E.mat'.\n",
      "100%|█████████████████████████████████████| 43.4M/43.4M [00:00<00:00, 20.2GB/s]\n",
      "SHA256 hash of downloaded file: bf67a40621b74b6af7a986c2f6edfff7fc2bbbca237aadd07b575893032998d1\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A07T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A07T.mat'.\n",
      "100%|█████████████████████████████████████| 42.8M/42.8M [00:00<00:00, 31.5GB/s]\n",
      "SHA256 hash of downloaded file: 43b6bbef0be78f0ac2b66cb2d9679091f1f5b7f0a5d4ebef73d2c7cc8e11aa96\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A07E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A07E.mat'.\n",
      "100%|█████████████████████████████████████| 42.2M/42.2M [00:00<00:00, 20.2GB/s]\n",
      "SHA256 hash of downloaded file: b9aaec73dcee002fab84ee98e938039a67bf6a3cbf4fc86d5d8df198cfe4c323\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A08T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A08T.mat'.\n",
      "100%|█████████████████████████████████████| 45.0M/45.0M [00:00<00:00, 15.7GB/s]\n",
      "SHA256 hash of downloaded file: 7a4b3bd602d5bc307d3f4527fca2cf076659e94aca584dd64f6286fd413a82f2\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A08E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A08E.mat'.\n",
      "100%|█████████████████████████████████████| 46.3M/46.3M [00:00<00:00, 23.7GB/s]\n",
      "SHA256 hash of downloaded file: 0eedbd89790c7d621c8eef68065ddecf80d437bbbcf60321d9253e2305f294f7\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A09T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A09T.mat'.\n",
      "100%|█████████████████████████████████████| 44.8M/44.8M [00:00<00:00, 43.2GB/s]\n",
      "SHA256 hash of downloaded file: b28d8a262c779c8cad9cc80ee6aa9c5691cfa6617c03befe490a090347ebd15c\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A09E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A09E.mat'.\n",
      "100%|█████████████████████████████████████| 44.8M/44.8M [00:00<00:00, 18.3GB/s]\n",
      "SHA256 hash of downloaded file: 5d79649a42df9d51215def8ffbdaf1c3f76c54b88b9bbaae721e8c6fd972cc36\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "dl.load_data()# Download all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "dl.load_data(subject_ids=[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function scale is deprecated; will be removed in 0.7.0. Use numpy.multiply instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "low_cut_hz = 4.\n",
    "high_cut_hz = 38.\n",
    "\n",
    "preprocessors = [\n",
    "            Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "            Preprocessor(scale, factor=1e6, apply_on_array=True),  # Convert from V to uV\n",
    "            Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
    "        ]\n",
    "\n",
    "dl.preprocess_data(preprocessors=preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "trials = dl.get_trials(start_offset=[0,0.5], end_offset=[0,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = get_epochs(trials['win_0'].split('session')['session_E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIGAScience Cho2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset_name=\"Cho2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Downloading data from 'ftp://parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100295/mat_data/s02.mat' to file '/Users/julian/mne_data/MNE-gigadb-data/gigadb/pub/10.5524/100001_101000/100295/mat_data/s02.mat'.\n",
      "100%|███████████████████████████████████████| 205M/205M [02:21<00:00, 1.45MB/s]\n",
      "SHA256 hash of downloaded file: 1ad1d82d9e409d85d520837377d88a89c086a4f526dba0ce0fe588b6e6e3659e\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Downloading data from 'ftp://parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100295/mat_data/s03.mat' to file '/Users/julian/mne_data/MNE-gigadb-data/gigadb/pub/10.5524/100001_101000/100295/mat_data/s03.mat'.\n",
      "100%|███████████████████████████████████████| 207M/207M [02:50<00:00, 1.21MB/s]\n",
      "SHA256 hash of downloaded file: f2b4e386c501add1bfd5b43767f2d684a7c1fa29f811d3a1876d4e5861377ebc\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/julian/Documents/python-gcpds.MI_prediction/Examples/TestDatasets.ipynb Celda 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/julian/Documents/python-gcpds.MI_prediction/Examples/TestDatasets.ipynb#ch0000045?line=0'>1</a>\u001b[0m dl\u001b[39m.\u001b[39;49mload_data()\n",
      "File \u001b[0;32m~/Documents/python-gcpds.MI_prediction/Examples/src/mi-prediction/MI_prediction/Utils/Datasets.py:50\u001b[0m, in \u001b[0;36mDataLoader.load_data\u001b[0;34m(self, subject_ids)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data\u001b[39m(\u001b[39mself\u001b[39m,subject_ids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m MOABBDataset(dataset_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_name, subject_ids\u001b[39m=\u001b[39;49msubject_ids)\n",
      "File \u001b[0;32m~/miniforge3/envs/MI_pred/lib/python3.9/site-packages/braindecode/datasets/moabb.py:108\u001b[0m, in \u001b[0;36mMOABBDataset.__init__\u001b[0;34m(self, dataset_name, subject_ids, dataset_kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, dataset_name, subject_ids, dataset_kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 108\u001b[0m     raws, description \u001b[39m=\u001b[39m fetch_data_with_moabb(dataset_name, subject_ids, dataset_kwargs)\n\u001b[1;32m    109\u001b[0m     all_base_ds \u001b[39m=\u001b[39m [BaseDataset(raw, row)\n\u001b[1;32m    110\u001b[0m                    \u001b[39mfor\u001b[39;00m raw, (_, row) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(raws, description\u001b[39m.\u001b[39miterrows())]\n\u001b[1;32m    111\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(all_base_ds)\n",
      "File \u001b[0;32m~/miniforge3/envs/MI_pred/lib/python3.9/site-packages/braindecode/datasets/moabb.py:90\u001b[0m, in \u001b[0;36mfetch_data_with_moabb\u001b[0;34m(dataset_name, subject_ids, dataset_kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m dataset \u001b[39m=\u001b[39m _find_dataset_in_moabb(dataset_name, dataset_kwargs)\n\u001b[1;32m     89\u001b[0m subject_id \u001b[39m=\u001b[39m [subject_ids] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(subject_ids, \u001b[39mint\u001b[39m) \u001b[39melse\u001b[39;00m subject_ids\n\u001b[0;32m---> 90\u001b[0m \u001b[39mreturn\u001b[39;00m _fetch_and_unpack_moabb_data(dataset, subject_id)\n",
      "File \u001b[0;32m~/miniforge3/envs/MI_pred/lib/python3.9/site-packages/braindecode/datasets/moabb.py:33\u001b[0m, in \u001b[0;36m_fetch_and_unpack_moabb_data\u001b[0;34m(dataset, subject_ids)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetch_and_unpack_moabb_data\u001b[39m(dataset, subject_ids):\n\u001b[0;32m---> 33\u001b[0m     data \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mget_data(subject_ids)\n\u001b[1;32m     34\u001b[0m     raws, subject_ids, session_ids, run_ids \u001b[39m=\u001b[39m [], [], [], []\n\u001b[1;32m     35\u001b[0m     \u001b[39mfor\u001b[39;00m subj_id, subj_data \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniforge3/envs/MI_pred/lib/python3.9/site-packages/moabb/datasets/base.py:113\u001b[0m, in \u001b[0;36mBaseDataset.get_data\u001b[0;34m(self, subjects)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m subject \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubject_list:\n\u001b[1;32m    112\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid subject \u001b[39m\u001b[39m{:d}\u001b[39;00m\u001b[39m given\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(subject))\n\u001b[0;32m--> 113\u001b[0m     data[subject] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_single_subject_data(subject)\n\u001b[1;32m    115\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniforge3/envs/MI_pred/lib/python3.9/site-packages/moabb/datasets/gigadb.py:109\u001b[0m, in \u001b[0;36mCho2017._get_single_subject_data\u001b[0;34m(self, subject)\u001b[0m\n\u001b[1;32m    105\u001b[0m eeg_data_r \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack([imagery_right \u001b[39m*\u001b[39m \u001b[39m1e-6\u001b[39m, data\u001b[39m.\u001b[39mimagery_event \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m])\n\u001b[1;32m    107\u001b[0m \u001b[39m# trials are already non continuous. edge artifact can appears but\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m# are likely to be present during rest / inter-trial activity\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m eeg_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mhstack(\n\u001b[1;32m    110\u001b[0m     [eeg_data_l, np\u001b[39m.\u001b[39;49mzeros((eeg_data_l\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], \u001b[39m500\u001b[39;49m)), eeg_data_r]\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m log\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    113\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTrials demeaned and stacked with zero buffer to create \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcontinuous data -- edge effects present\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m )\n\u001b[1;32m    117\u001b[0m info \u001b[39m=\u001b[39m create_info(ch_names\u001b[39m=\u001b[39mch_names, ch_types\u001b[39m=\u001b[39mch_types, sfreq\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39msrate)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/MI_pred/lib/python3.9/site-packages/numpy/core/shape_base.py:345\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39mconcatenate(arrs, \u001b[39m0\u001b[39m)\n\u001b[1;32m    344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dl.load_data()# Download all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 events found\n",
      "Event IDs: [1 2]\n"
     ]
    }
   ],
   "source": [
    "dl.load_data(subject_ids=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function scale is deprecated; will be removed in 0.7.0. Use numpy.multiply instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "low_cut_hz = 4.\n",
    "high_cut_hz = 38.\n",
    "\n",
    "preprocessors = [\n",
    "            Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "            Preprocessor(scale, factor=1e6, apply_on_array=True),  # Convert from V to uV\n",
    "            Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
    "        ]\n",
    "\n",
    "dl.preprocess_data(preprocessors=preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
      "Adding metadata with 4 columns\n",
      "200 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 200 events and 1536 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
      "Adding metadata with 4 columns\n",
      "200 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 200 events and 1536 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "trials = dl.get_trials(start_offset=[0,0.5], end_offset=[0,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = get_epochs(trials['win_0'].split('session')['session_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr,ytr = get_runs(trials['win_0'].split('session')['session_0'], n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['run_0', 'run_1', 'run_2', 'run_3', 'run_4'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MI_pred",
   "language": "python",
   "name": "mi_pred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
