{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining MI_prediction from git+https://github.com/UN-GCPDS/python-gcpds.MI_prediction.git#egg=MI_prediction\n",
      "  Updating ./src/mi-prediction clone\n",
      "  Running command git fetch -q --tags\n",
      "  Running command git reset --hard -q 74147ff6cf572dfa3917f9ec85441b0eb42aa0e1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: moabb in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from MI_prediction) (0.4.6)\n",
      "Requirement already satisfied: braindecode in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from MI_prediction) (0.6)\n",
      "Requirement already satisfied: skorch in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (0.11.0)\n",
      "Requirement already satisfied: mne in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (1.0.3)\n",
      "Requirement already satisfied: h5py in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (3.7.0)\n",
      "Requirement already satisfied: pandas in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (1.4.3)\n",
      "Requirement already satisfied: matplotlib in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (3.5.2)\n",
      "Requirement already satisfied: numpy in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (1.23.1)\n",
      "Requirement already satisfied: scipy in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from braindecode->MI_prediction) (1.8.1)\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (1.1.1)\n",
      "Requirement already satisfied: seaborn>=0.9 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (0.11.2)\n",
      "Requirement already satisfied: coverage<6.0,>=5.5 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (5.5)\n",
      "Requirement already satisfied: pyriemann>=0.2.6 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.15.1 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (2.28.1)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.62 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (4.64.0)\n",
      "Requirement already satisfied: pooch<2.0,>=1.6 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (1.6.0)\n",
      "Requirement already satisfied: PyYAML<6.0,>=5.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from moabb->MI_prediction) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from matplotlib->braindecode->MI_prediction) (4.34.4)\n",
      "Requirement already satisfied: jinja2 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from mne->braindecode->MI_prediction) (3.1.2)\n",
      "Requirement already satisfied: decorator in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from mne->braindecode->MI_prediction) (5.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from pandas->braindecode->MI_prediction) (2022.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from pooch<2.0,>=1.6->moabb->MI_prediction) (1.4.4)\n",
      "Requirement already satisfied: joblib in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from pyriemann>=0.2.6->moabb->MI_prediction) (1.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from requests<3.0.0,>=2.15.1->moabb->MI_prediction) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from requests<3.0.0,>=2.15.1->moabb->MI_prediction) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from requests<3.0.0,>=2.15.1->moabb->MI_prediction) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from requests<3.0.0,>=2.15.1->moabb->MI_prediction) (3.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from scikit-learn<2.0,>=1.0->moabb->MI_prediction) (3.1.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from skorch->braindecode->MI_prediction) (0.8.10)\n",
      "Requirement already satisfied: six>=1.5 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->braindecode->MI_prediction) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages (from jinja2->mne->braindecode->MI_prediction) (2.1.1)\n",
      "Installing collected packages: MI_prediction\n",
      "  Attempting uninstall: MI_prediction\n",
      "    Found existing installation: MI-prediction 0.1\n",
      "    Uninstalling MI-prediction-0.1:\n",
      "      Successfully uninstalled MI-prediction-0.1\n",
      "  Running setup.py develop for MI_prediction\n",
      "Successfully installed MI_prediction-0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install -U git+https://github.com/UN-GCPDS/python-gcpds.MI_prediction.git &> /dev/null\n",
    "%pip install -e git+https://github.com/UN-GCPDS/python-gcpds.MI_prediction.git#egg=MI_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MI_prediction.Utils.Datasets import DataLoader, get_epochs, get_runs\n",
    "from braindecode.preprocessing.preprocess import exponential_moving_standardize, preprocess, Preprocessor, scale\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCI IIa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset_name=\"BNCI2014001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A03T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A03T.mat'.\n",
      "100%|█████████████████████████████████████| 44.1M/44.1M [00:00<00:00, 20.2GB/s]\n",
      "SHA256 hash of downloaded file: 7e731ee8b681d5da6ecb11ae1d4e64b1653c7f15aad5d6b7620b25ce53141e80\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A03E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A03E.mat'.\n",
      "100%|█████████████████████████████████████| 42.3M/42.3M [00:00<00:00, 19.9GB/s]\n",
      "SHA256 hash of downloaded file: d4229267ec7624fa8bd3af5cbebac17f415f7c722de6cb676748f8cb3b717d97\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A04T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A04T.mat'.\n",
      "100%|█████████████████████████████████████| 37.2M/37.2M [00:00<00:00, 15.3GB/s]\n",
      "SHA256 hash of downloaded file: 15850d81b95fc88cc8b9589eb9b713d49fa071e28adaf32d675b3eaa30591d6e\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A04E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A04E.mat'.\n",
      "100%|█████████████████████████████████████| 41.7M/41.7M [00:00<00:00, 43.2GB/s]\n",
      "SHA256 hash of downloaded file: 81916dff2c12997974ba50ffc311da006ea66e525010d010765f0047e771c86a\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A05T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A05T.mat'.\n",
      "100%|█████████████████████████████████████| 42.5M/42.5M [00:00<00:00, 25.6GB/s]\n",
      "SHA256 hash of downloaded file: 77387d3b669f4ed9a7c1dac4dcba4c2c40c8910bae20fb961bb7cf5a94912950\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A05E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A05E.mat'.\n",
      "100%|█████████████████████████████████████| 44.4M/44.4M [00:00<00:00, 24.0GB/s]\n",
      "SHA256 hash of downloaded file: 8b357470865610c28b2f1d351beac247a56a856f02b2859d650736eb2ef77808\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A06T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A06T.mat'.\n",
      "100%|█████████████████████████████████████| 44.6M/44.6M [00:00<00:00, 15.8GB/s]\n",
      "SHA256 hash of downloaded file: 4dc3be1b0d60279134d1220323c73c68cf73799339a7fb224087a3c560a9a7e2\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A06E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A06E.mat'.\n",
      "100%|█████████████████████████████████████| 43.4M/43.4M [00:00<00:00, 20.2GB/s]\n",
      "SHA256 hash of downloaded file: bf67a40621b74b6af7a986c2f6edfff7fc2bbbca237aadd07b575893032998d1\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A07T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A07T.mat'.\n",
      "100%|█████████████████████████████████████| 42.8M/42.8M [00:00<00:00, 31.5GB/s]\n",
      "SHA256 hash of downloaded file: 43b6bbef0be78f0ac2b66cb2d9679091f1f5b7f0a5d4ebef73d2c7cc8e11aa96\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A07E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A07E.mat'.\n",
      "100%|█████████████████████████████████████| 42.2M/42.2M [00:00<00:00, 20.2GB/s]\n",
      "SHA256 hash of downloaded file: b9aaec73dcee002fab84ee98e938039a67bf6a3cbf4fc86d5d8df198cfe4c323\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A08T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A08T.mat'.\n",
      "100%|█████████████████████████████████████| 45.0M/45.0M [00:00<00:00, 15.7GB/s]\n",
      "SHA256 hash of downloaded file: 7a4b3bd602d5bc307d3f4527fca2cf076659e94aca584dd64f6286fd413a82f2\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A08E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A08E.mat'.\n",
      "100%|█████████████████████████████████████| 46.3M/46.3M [00:00<00:00, 23.7GB/s]\n",
      "SHA256 hash of downloaded file: 0eedbd89790c7d621c8eef68065ddecf80d437bbbcf60321d9253e2305f294f7\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A09T.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A09T.mat'.\n",
      "100%|█████████████████████████████████████| 44.8M/44.8M [00:00<00:00, 43.2GB/s]\n",
      "SHA256 hash of downloaded file: b28d8a262c779c8cad9cc80ee6aa9c5691cfa6617c03befe490a090347ebd15c\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A09E.mat' to file '/Users/julian/mne_data/MNE-bnci-data/database/data-sets/001-2014/A09E.mat'.\n",
      "100%|█████████████████████████████████████| 44.8M/44.8M [00:00<00:00, 18.3GB/s]\n",
      "SHA256 hash of downloaded file: 5d79649a42df9d51215def8ffbdaf1c3f76c54b88b9bbaae721e8c6fd972cc36\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "dl.load_data()# Download all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "dl.load_data(subject_ids=[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function scale is deprecated; will be removed in 0.7.0. Use numpy.multiply instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "low_cut_hz = 4.\n",
    "high_cut_hz = 38.\n",
    "\n",
    "preprocessors = [\n",
    "            Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "            Preprocessor(scale, factor=1e6, apply_on_array=True),  # Convert from V to uV\n",
    "            Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
    "        ]\n",
    "\n",
    "dl.preprocess_data(preprocessors=preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Adding metadata with 4 columns\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 48 events and 1000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "trials = dl.get_trials(start_offset=[0,0.5], end_offset=[0,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = get_epochs(trials['win_0'].split('session')['session_E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIGAScience Cho2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset_name=\"Cho2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Downloading data from 'ftp://parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100295/mat_data/s42.mat' to file '/Users/julian/mne_data/MNE-gigadb-data/gigadb/pub/10.5524/100001_101000/100295/mat_data/s42.mat'.\n",
      "100%|███████████████████████████████████████| 202M/202M [01:30<00:00, 2.22MB/s]\n",
      "SHA256 hash of downloaded file: fe60fdfc6120d9716510b8a5a056c4bf0bf9b77782eed806a3ccf7a50bc040e5\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Downloading data from 'ftp://parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100295/mat_data/s43.mat' to file '/Users/julian/mne_data/MNE-gigadb-data/gigadb/pub/10.5524/100001_101000/100295/mat_data/s43.mat'.\n",
      "100%|███████████████████████████████████████| 205M/205M [02:48<00:00, 1.22MB/s]\n",
      "SHA256 hash of downloaded file: 7d4d7f93acf84569669ff2655364e0ddf7018d68e7d8b5e2060f0ec479507ea0\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Downloading data from 'ftp://parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100295/mat_data/s44.mat' to file '/Users/julian/mne_data/MNE-gigadb-data/gigadb/pub/10.5524/100001_101000/100295/mat_data/s44.mat'.\n",
      "100%|███████████████████████████████████████| 209M/209M [02:34<00:00, 1.35MB/s]\n",
      "SHA256 hash of downloaded file: b0433df98a59f5c354743d97e5ffea422cb9bfa69cf025f828d4e038872d3c7d\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Downloading data from 'ftp://parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100295/mat_data/s45.mat' to file '/Users/julian/mne_data/MNE-gigadb-data/gigadb/pub/10.5524/100001_101000/100295/mat_data/s45.mat'.\n",
      "100%|███████████████████████████████████████| 208M/208M [01:40<00:00, 2.06MB/s]\n",
      "SHA256 hash of downloaded file: 1d679a6daba9a60160eb080abe7532bab49f78f6ebe7bc79f817512d6b9f855b\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Downloading data from 'ftp://parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100295/mat_data/s47.mat' to file '/Users/julian/mne_data/MNE-gigadb-data/gigadb/pub/10.5524/100001_101000/100295/mat_data/s47.mat'.\n",
      "100%|███████████████████████████████████████| 202M/202M [02:39<00:00, 1.26MB/s]\n",
      "SHA256 hash of downloaded file: e5d5161a85b645839ec3c23b5ef8e334f423aab132cd6b938d96eccd73ed5137\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Downloading data from 'ftp://parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100295/mat_data/s48.mat' to file '/Users/julian/mne_data/MNE-gigadb-data/gigadb/pub/10.5524/100001_101000/100295/mat_data/s48.mat'.\n",
      "100%|███████████████████████████████████████| 206M/206M [01:48<00:00, 1.89MB/s]\n",
      "SHA256 hash of downloaded file: ad01fd29a2f358204b0f528e78dbb909d35ad4304b3fa222dff90e759941a287\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Downloading data from 'ftp://parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100295/mat_data/s50.mat' to file '/Users/julian/mne_data/MNE-gigadb-data/gigadb/pub/10.5524/100001_101000/100295/mat_data/s50.mat'.\n",
      "100%|███████████████████████████████████████| 205M/205M [02:09<00:00, 1.58MB/s]\n",
      "SHA256 hash of downloaded file: b5df79bb64eb585ff01eb77cc176c9a02964c564dd40a4eeec7764b510950d40\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Downloading data from 'ftp://parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100295/mat_data/s51.mat' to file '/Users/julian/mne_data/MNE-gigadb-data/gigadb/pub/10.5524/100001_101000/100295/mat_data/s51.mat'.\n",
      "100%|███████████████████████████████████████| 200M/200M [02:33<00:00, 1.30MB/s]\n",
      "SHA256 hash of downloaded file: 0c09887cc122d4a0c043d2304af1537a293fe86562b4296ec0e75f5bf2e95fbb\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "Downloading data from 'ftp://parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100295/mat_data/s52.mat' to file '/Users/julian/mne_data/MNE-gigadb-data/gigadb/pub/10.5524/100001_101000/100295/mat_data/s52.mat'.\n",
      "100%|███████████████████████████████████████| 207M/207M [02:24<00:00, 1.43MB/s]\n",
      "SHA256 hash of downloaded file: 94840189e02d45ccca5d340bde6ca7f3e4c726acaf9749f6b9c6053ecb147f50\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "240 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "240 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n",
      "200 events found\n",
      "Event IDs: [1 2]\n"
     ]
    }
   ],
   "source": [
    "dl.load_data()# Download all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 events found\n",
      "Event IDs: [1 2]\n"
     ]
    }
   ],
   "source": [
    "dl.load_data(subject_ids=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julian/miniforge3/envs/MI_pred/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function scale is deprecated; will be removed in 0.7.0. Use numpy.multiply instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 38 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 38.00 Hz\n",
      "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
      "- Filter length: 845 samples (1.650 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "low_cut_hz = 4.\n",
    "high_cut_hz = 38.\n",
    "\n",
    "preprocessors = [\n",
    "            Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "            Preprocessor(scale, factor=1e6, apply_on_array=True),  # Convert from V to uV\n",
    "            Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
    "        ]\n",
    "\n",
    "dl.preprocess_data(preprocessors=preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
      "Adding metadata with 4 columns\n",
      "200 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 200 events and 1536 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['left_hand', 'right_hand']\n",
      "Adding metadata with 4 columns\n",
      "200 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 200 events and 1536 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "trials = dl.get_trials(start_offset=[0,0.5], end_offset=[0,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = get_epochs(trials['win_0'].split('session')['session_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr,ytr = get_runs(trials['win_0'].split('session')['session_0'], n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['run_0', 'run_1', 'run_2', 'run_3', 'run_4'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MI_pred",
   "language": "python",
   "name": "mi_pred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
