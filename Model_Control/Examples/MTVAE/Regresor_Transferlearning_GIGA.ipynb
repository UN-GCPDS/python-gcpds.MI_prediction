{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaWHnLz68-jG"
      },
      "source": [
        "## IMPORTAMOS LAS LIBRERIAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bVlVFM018DN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from scipy.signal import resample\n",
        "!pip install braindecode===0.7\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install --upgrade tensorflow\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "%pip install -e git+https://github.com/UN-GCPDS/python-gcpds.MI_prediction.git#egg=MI_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjE6n2fKeLPi"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9-P0w2X82TW",
        "outputId": "bf117d54-02e0-4a12-ae7f-dfac65b487d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "/usr/local/lib/python3.10/dist-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "from src.prediction.Model_Control.Global_Class.Global_Class import ModelControl\n",
        "from src.prediction.Model_Control.Global_Class.Global_Class import DatasetControl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUWxUiF-9C5i"
      },
      "outputs": [],
      "source": [
        "from braindecode.datasets.moabb import MOABBDataset\n",
        "from braindecode.preprocessing.preprocess import (exponential_moving_standardize, preprocess, Preprocessor, scale)\n",
        "from braindecode.preprocessing.windowers import create_windows_from_events\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OPlffUu9RFJ"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DklmUXqdHQW0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D,Conv2DTranspose\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Input, Flatten, Reshape\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWW9bf9R9Yej"
      },
      "outputs": [],
      "source": [
        "\n",
        "### TENEMOS LOS SUJETOS Y LOS TARGET PARA CADA UNO\n",
        "subjects =[1,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
        " 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52]\n",
        "### ACCURACY PARA LA TAREA DE REGRESIÓN\n",
        "acc_subj_MTVAE = [89.0,66.5,98.0,90.0,99.0,84.0,72.0,79.5,77.5,90.5,73.5,75.5,96.5,98.0,83.5,76.5,78.5,78.0,80.5,75.0,63.5,82.0,95.5, 78.0,87.0,96.5,78.5,90.0,81.0,78.0,79.0,79.0,70.5,85.5,78.0,87.0,66.5,80.0,77.5,96.0,79.5,94.0,95.0,75.0,83.0,96.0,100.0,76.5,78.5]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiWe7zPB9U7Y"
      },
      "source": [
        "## CARGAMOS LA BASE DE DATOS PREPROCESADA Y LOS SUJETOS CORRESPONDIENTES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ueer3xl-E46"
      },
      "outputs": [],
      "source": [
        "### FUNCIONES PARA ADECUAR LA BASE DE DATOS PARA EL ENTRENO DEL MODELO EN LA TAREA DE REGRESIÓN\n",
        "def reemplazar_valor(arr, valor_original, nuevo_valor):\n",
        "    arr[arr == valor_original] = nuevo_valor\n",
        "    return arr\n",
        "\n",
        "def bi_class_data(y,sbj):\n",
        "    ## NOS QUEDAMOS CON LOS QUE SON DE CLASE 1 ES DECIR RESTING\n",
        "    # Define la condición para eliminar valores del segundo arreglo\n",
        "\n",
        "    acc = acc_subj_MTVAE[subjects.index(sbj)]\n",
        "    y_acc = np.full(y.shape[0], acc)\n",
        "\n",
        "    return y_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8JUC5sDG11M"
      },
      "source": [
        "## ENTRENAMOS LOS MODELOS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELO MTVAE ADECUADO PARA TAREA DE REGRESIÓN"
      ],
      "metadata": {
        "id": "d1x22PB0HzPn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8MCQHbIW21M"
      },
      "outputs": [],
      "source": [
        "class reparametrize(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        mean, log_var = inputs\n",
        "        eta = tf.random.normal(tf.shape(log_var))\n",
        "        sigma = tf.math.exp(log_var / 2)\n",
        "        return  mean + sigma * eta\n",
        "\n",
        "def MTVAE_KL(Chans = 22, Samples = 250, dropoutRate = 0.5, l1 = 0, l2 = 0):\n",
        "\n",
        "    filters      = (1,40)\n",
        "    strid        = (1,15)\n",
        "    pool         = (1,75)\n",
        "    bias_spatial = True\n",
        "\n",
        "    input_main   = Input((Chans, Samples, 1))\n",
        "    block1       = Conv2D(40, filters, strides=(1,2),\n",
        "                                 input_shape=(Chans, Samples, 1),kernel_regularizer=l1_l2(l1=l1,l2=l2),\n",
        "                                 name='Conv2D_1',\n",
        "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
        "    block1       = Conv2D(40, (Chans, 1), use_bias=bias_spatial, kernel_regularizer=l1_l2(l1=l1,l2=l2),\n",
        "                          name='Conv2D_2',\n",
        "                          kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
        "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.1)(block1)\n",
        "    Act1         = Activation('elu')(block1)\n",
        "    block1       = AveragePooling2D(pool_size=pool, strides=strid)(Act1)\n",
        "    block1       = Dropout(dropoutRate,name='bottleneck')(block1)\n",
        "\n",
        "    mu           = Dense(40,name='mu')(block1)\n",
        "    log_var      = Dense(40,name='log_var')(block1)\n",
        "    codings      = reparametrize(name='Code')([mu, log_var])\n",
        "\n",
        "    ConvC        = Conv2D(1, (1, block1.shape[2]),kernel_regularizer=l1_l2(l1=l1,l2=l2),kernel_constraint = max_norm(0.5, axis=(0,1,2)),name='ouput')(block1)\n",
        "    flat          = Flatten(name='output')(ConvC)\n",
        "    softmax      = Activation('linear',name='out_activation')(flat)\n",
        "\n",
        "    block2       = Conv2DTranspose(40, pool,strides=strid,activation='tanh', kernel_regularizer=l1_l2(l1=l1,l2=l2),\n",
        "                          kernel_constraint = max_norm(2., axis=(0,1,2)))(codings)\n",
        "    block2       = Resizing(block2.shape[1], Act1.shape[2])(block2)\n",
        "    block2       = Conv2DTranspose(40, (Chans, 1), use_bias=bias_spatial, kernel_regularizer=l1_l2(l1=l1,l2=l2),\n",
        "                          kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
        "    block2       = Conv2DTranspose(1, filters,strides=(1,2),\n",
        "                                 input_shape=(Chans, Samples, 1),kernel_regularizer=l1_l2(l1=l1,l2=l2),\n",
        "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
        "\n",
        "    model = Model(inputs=input_main, outputs=[block2,softmax])\n",
        "\n",
        "    var_flat      = Flatten()(log_var)\n",
        "    mu_flat       = Flatten()(mu)\n",
        "\n",
        "    KL = -0.5 * tf.keras.backend.sum( 1 + var_flat - tf.keras.backend.exp(var_flat) - tf.keras.backend.square(mu_flat),axis=-1)\n",
        "    model.add_loss(tf.keras.backend.mean(KL)/var_flat.shape[-1])#Chans*Samples)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CARGAMOS LA BASE DE DATOS POR RUN"
      ],
      "metadata": {
        "id": "AInB2Ee2Nep-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_qjYk1idPwg",
        "outputId": "7eceb412-aa2f-4ec6-ec38-bb48106ca0f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-3f7b4ae148d6>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y_data_total = np.array(y_data_total)\n",
            "<ipython-input-10-3f7b4ae148d6>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_data_total = np.array(x_data_total)\n"
          ]
        }
      ],
      "source": [
        "y_data_total = pickle.load(open('/content/drive/MyDrive/EEG_DATA/GIGA_DATASET/y_regresor.pkl', 'rb'))\n",
        "x_data_total = pickle.load(open('/content/drive/MyDrive/EEG_DATA/GIGA_DATASET/x_regresor.pkl', 'rb'))\n",
        "y_data_total = np.array(y_data_total)\n",
        "x_data_total = np.array(x_data_total)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### ITERAMOS PARA OBTENER ARREGLO CON LOS DATOS\n",
        "y_data_runs = []\n",
        "x_data_runs = []\n",
        "\n",
        "for i in range(len(y_data_total)):\n",
        "    y_train_run_0,y_train_run_1,y_train_run_2,y_train_run_3,y_train_run_4 = y_data_total[i][:40],y_data_total[i][40:80],y_data_total[i][80:120],y_data_total[i][120:160],y_data_total[i][160:199]\n",
        "    x_train_run_0,x_train_run_1,x_train_run_2,x_train_run_3,x_train_run_4 = x_data_total[i][:40],x_data_total[i][40:80],x_data_total[i][80:120],x_data_total[i][120:160],x_data_total[i][160:199]\n",
        "    y_data_runs.append([y_train_run_0,y_train_run_1,y_train_run_2,y_train_run_3,y_train_run_4])\n",
        "    x_data_runs.append([x_train_run_0,x_train_run_1,x_train_run_2,x_train_run_3,x_train_run_4])"
      ],
      "metadata": {
        "id": "gDneNoE-Nhw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_data_runs = np.array(y_data_runs)\n",
        "x_data_runs = np.array(x_data_runs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY5_SfKuRweN",
        "outputId": "0583cc4a-86e4-4fcf-9bc9-58d69cc8f6c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-874f55c27c53>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y_data_runs = np.array(y_data_runs)\n",
            "<ipython-input-12-874f55c27c53>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_data_runs = np.array(x_data_runs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data_runs[:,0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjjCwY44R3sF",
        "outputId": "caf80e72-7a47-4bd7-96ad-c18bc141e0a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data_runs[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t66y257hPt9A",
        "outputId": "e25e2a8a-d218-4d34-89de-f083937ec95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 64, 256, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_data_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQLO3JMPQJCg",
        "outputId": "0c85bf67-60c1-4d19-8b7c-6698b2a89852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUNS"
      ],
      "metadata": {
        "id": "CtIRJQ27RQQM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6QmJkGUMyTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1fff1e-fc3f-4785-bc6d-2d389b44284c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sujeto :  1\n",
            "sujeto :  2\n",
            "sujeto :  3\n",
            "sujeto :  4\n",
            "sujeto :  5\n",
            "sujeto :  6\n",
            "sujeto :  7\n",
            "sujeto :  8\n",
            "sujeto :  9\n",
            "sujeto :  10\n",
            "sujeto :  11\n",
            "sujeto :  12\n",
            "sujeto :  13\n",
            "sujeto :  14\n",
            "sujeto :  15\n",
            "sujeto :  16\n",
            "sujeto :  17\n",
            "sujeto :  18\n",
            "sujeto :  19\n",
            "sujeto :  20\n",
            "sujeto :  21\n",
            "sujeto :  22\n",
            "sujeto :  23\n",
            "sujeto :  24\n",
            "sujeto :  25\n",
            "sujeto :  26\n",
            "sujeto :  27\n",
            "sujeto :  28\n",
            "sujeto :  29\n",
            "sujeto :  30\n",
            "sujeto :  31\n",
            "sujeto :  33\n",
            "sujeto :  34\n",
            "sujeto :  35\n",
            "sujeto :  36\n",
            "sujeto :  37\n",
            "sujeto :  38\n",
            "sujeto :  39\n",
            "sujeto :  40\n",
            "sujeto :  41\n",
            "sujeto :  42\n",
            "sujeto :  43\n",
            "sujeto :  44\n",
            "sujeto :  45\n",
            "sujeto :  47\n",
            "sujeto :  48\n",
            "sujeto :  50\n",
            "sujeto :  51\n",
            "sujeto :  52\n"
          ]
        }
      ],
      "source": [
        "## COPIAMOS EL SET DE DATOS\n",
        "## LISTA PARA AGREGAR LA PREDICCIÓN DEL SUJETO\n",
        "for i in range(len(y_data_total)):\n",
        "  print(\"sujeto : \",subjects[i])\n",
        "  ### ELIMINAMOS EL SUJETO DEL SET DE DATOS PARA ENTRENAR EL MODELO\n",
        "  y_data = y_data_runs[:,2]\n",
        "  x_data = x_data_runs[:,2]\n",
        "  y_data_total_copy = np.copy(y_data)\n",
        "  x_data_total_copy = np.copy(x_data)\n",
        "  y_data_total_copy = np.delete(y_data_total_copy, i)\n",
        "  x_data_total_copy = np.delete(x_data_total_copy, i)\n",
        "  ### GENERAMOS EL SET DE DATOS DE ENTRENO Y VALIDACIÓN SIN TENER EN CUENTA EL SUJETO\n",
        "  y_train = y_data_total_copy[0]\n",
        "  x_train = x_data_total_copy[0]\n",
        "  for a in range(1,len(y_data_total_copy)):\n",
        "      y_train = np.concatenate([y_train,y_data_total_copy[a]])\n",
        "      x_train = np.concatenate([x_train,x_data_total_copy[a]])\n",
        "  X_train_, X_test_, y_train_, y_test_ = train_test_split(x_train, y_train, test_size=0.20, random_state=42)\n",
        "  #### generamos el modelo\n",
        "  MODEL = MTVAE_KL(Chans = 64, Samples = 256, dropoutRate = 0.5)\n",
        "  ### COMPILAMOS EL MODELO\n",
        "  MODEL.compile(optimizer='adam',loss=['mse','mse'], metrics= ['mse'])\n",
        "  history = MODEL.fit(X_train_,[X_train_,y_train_],epochs= 60,verbose=0,validation_data=(X_test_, [X_test_,y_test_]),callbacks=[tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/model_run2_'+str(i)+'.h5', save_best_only=True, monitor='val_out_activation_loss')])\n",
        "  ### GRAFICAMOS LAS CURVAS DE OVERFITTING\n",
        "  loss = history.history['out_activation_mse']\n",
        "  val_loss = history.history['val_out_activation_mse']\n",
        "  epochs = range(1, len(loss) + 1)\n",
        "  # break\n",
        "  plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  plt.ylim([0, np.max(val_loss)])\n",
        "  plt.title('Curvas de perdida MSE ' +str(subjects[i]) )\n",
        "  save_file_path = os.path.join('/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/', 'REGRESOR_MI_run2' +str(i+1)  + '.png')\n",
        "  plt.savefig(save_file_path)\n",
        "  plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## COPIAMOS EL SET DE DATOS\n",
        "## LISTA PARA AGREGAR LA PREDICCIÓN DEL SUJETO\n",
        "for i in range(len(y_data_total)):\n",
        "  print(\"sujeto : \",subjects[i])\n",
        "  ### ELIMINAMOS EL SUJETO DEL SET DE DATOS PARA ENTRENAR EL MODELO\n",
        "  y_data = y_data_runs[:,3]\n",
        "  x_data = x_data_runs[:,3]\n",
        "  y_data_total_copy = np.copy(y_data)\n",
        "  x_data_total_copy = np.copy(x_data)\n",
        "  y_data_total_copy = np.delete(y_data_total_copy, i)\n",
        "  x_data_total_copy = np.delete(x_data_total_copy, i)\n",
        "  ### GENERAMOS EL SET DE DATOS DE ENTRENO Y VALIDACIÓN SIN TENER EN CUENTA EL SUJETO\n",
        "  y_train = y_data_total_copy[0]\n",
        "  x_train = x_data_total_copy[0]\n",
        "  for a in range(1,len(y_data_total_copy)):\n",
        "      y_train = np.concatenate([y_train,y_data_total_copy[a]])\n",
        "      x_train = np.concatenate([x_train,x_data_total_copy[a]])\n",
        "  X_train_, X_test_, y_train_, y_test_ = train_test_split(x_train, y_train, test_size=0.20, random_state=42)\n",
        "  #### generamos el modelo\n",
        "  MODEL = MTVAE_KL(Chans = 64, Samples = 256, dropoutRate = 0.5)\n",
        "  ### COMPILAMOS EL MODELO\n",
        "  MODEL.compile(optimizer='adam',loss=['mse','mse'], metrics= ['mse'])\n",
        "  history = MODEL.fit(X_train_,[X_train_,y_train_],epochs= 60,verbose=0,validation_data=(X_test_, [X_test_,y_test_]),callbacks=[tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/model_run3_'+str(i)+'.h5', save_best_only=True, monitor='val_out_activation_loss')])\n",
        "  ### GRAFICAMOS LAS CURVAS DE OVERFITTING\n",
        "  loss = history.history['out_activation_mse']\n",
        "  val_loss = history.history['val_out_activation_mse']\n",
        "  epochs = range(1, len(loss) + 1)\n",
        "  # break\n",
        "  plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  plt.ylim([0, np.max(val_loss)])\n",
        "  plt.title('Curvas de perdida MSE ' +str(subjects[i]) )\n",
        "  save_file_path = os.path.join('/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/', 'REGRESOR_MI_run3' +str(i+1)  + '.png')\n",
        "  plt.savefig(save_file_path)\n",
        "  plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h381aebtlYqp",
        "outputId": "5a0281e5-95a4-4816-b09d-2b3ac7d094d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sujeto :  1\n",
            "sujeto :  2\n",
            "sujeto :  3\n",
            "sujeto :  4\n",
            "sujeto :  5\n",
            "sujeto :  6\n",
            "sujeto :  7\n",
            "sujeto :  8\n",
            "sujeto :  9\n",
            "sujeto :  10\n",
            "sujeto :  11\n",
            "sujeto :  12\n",
            "sujeto :  13\n",
            "sujeto :  14\n",
            "sujeto :  15\n",
            "sujeto :  16\n",
            "sujeto :  17\n",
            "sujeto :  18\n",
            "sujeto :  19\n",
            "sujeto :  20\n",
            "sujeto :  21\n",
            "sujeto :  22\n",
            "sujeto :  23\n",
            "sujeto :  24\n",
            "sujeto :  25\n",
            "sujeto :  26\n",
            "sujeto :  27\n",
            "sujeto :  28\n",
            "sujeto :  29\n",
            "sujeto :  30\n",
            "sujeto :  31\n",
            "sujeto :  33\n",
            "sujeto :  34\n",
            "sujeto :  35\n",
            "sujeto :  36\n",
            "sujeto :  37\n",
            "sujeto :  38\n",
            "sujeto :  39\n",
            "sujeto :  40\n",
            "sujeto :  41\n",
            "sujeto :  42\n",
            "sujeto :  43\n",
            "sujeto :  44\n",
            "sujeto :  45\n",
            "sujeto :  47\n",
            "sujeto :  48\n",
            "sujeto :  50\n",
            "sujeto :  51\n",
            "sujeto :  52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## COPIAMOS EL SET DE DATOS\n",
        "## LISTA PARA AGREGAR LA PREDICCIÓN DEL SUJETO\n",
        "for i in range(len(y_data_total)):\n",
        "  print(\"sujeto : \",subjects[i])\n",
        "  ### ELIMINAMOS EL SUJETO DEL SET DE DATOS PARA ENTRENAR EL MODELO\n",
        "  y_data = y_data_runs[:,4]\n",
        "  x_data = x_data_runs[:,4]\n",
        "  y_data_total_copy = np.copy(y_data)\n",
        "  x_data_total_copy = np.copy(x_data)\n",
        "  y_data_total_copy = np.delete(y_data_total_copy, i)\n",
        "  x_data_total_copy = np.delete(x_data_total_copy, i)\n",
        "  ### GENERAMOS EL SET DE DATOS DE ENTRENO Y VALIDACIÓN SIN TENER EN CUENTA EL SUJETO\n",
        "  y_train = y_data_total_copy[0]\n",
        "  x_train = x_data_total_copy[0]\n",
        "  for a in range(1,len(y_data_total_copy)):\n",
        "      y_train = np.concatenate([y_train,y_data_total_copy[a]])\n",
        "      x_train = np.concatenate([x_train,x_data_total_copy[a]])\n",
        "  X_train_, X_test_, y_train_, y_test_ = train_test_split(x_train, y_train, test_size=0.20, random_state=42)\n",
        "  #### generamos el modelo\n",
        "  MODEL = MTVAE_KL(Chans = 64, Samples = 256, dropoutRate = 0.5)\n",
        "  ### COMPILAMOS EL MODELO\n",
        "  MODEL.compile(optimizer='adam',loss=['mse','mse'], metrics= ['mse'])\n",
        "  history = MODEL.fit(X_train_,[X_train_,y_train_],epochs= 60,verbose=0,validation_data=(X_test_, [X_test_,y_test_]),callbacks=[tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/model_run4_'+str(i)+'.h5', save_best_only=True, monitor='val_out_activation_loss')])\n",
        "  ### GRAFICAMOS LAS CURVAS DE OVERFITTING\n",
        "  loss = history.history['out_activation_mse']\n",
        "  val_loss = history.history['val_out_activation_mse']\n",
        "  epochs = range(1, len(loss) + 1)\n",
        "  # break\n",
        "  plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  plt.ylim([0, np.max(val_loss)])\n",
        "  plt.title('Curvas de perdida MSE ' +str(subjects[i]) )\n",
        "  save_file_path = os.path.join('/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/', 'REGRESOR_MI_run4' +str(i+1)  + '.png')\n",
        "  plt.savefig(save_file_path)\n",
        "  plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCtou0jNlbyU",
        "outputId": "d7272822-12c3-42b9-eb79-4606619e9c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sujeto :  1\n",
            "sujeto :  2\n",
            "sujeto :  3\n",
            "sujeto :  4\n",
            "sujeto :  5\n",
            "sujeto :  6\n",
            "sujeto :  7\n",
            "sujeto :  8\n",
            "sujeto :  9\n",
            "sujeto :  10\n",
            "sujeto :  11\n",
            "sujeto :  12\n",
            "sujeto :  13\n",
            "sujeto :  14\n",
            "sujeto :  15\n",
            "sujeto :  16\n",
            "sujeto :  17\n",
            "sujeto :  18\n",
            "sujeto :  19\n",
            "sujeto :  20\n",
            "sujeto :  21\n",
            "sujeto :  22\n",
            "sujeto :  23\n",
            "sujeto :  24\n",
            "sujeto :  25\n",
            "sujeto :  26\n",
            "sujeto :  27\n",
            "sujeto :  28\n",
            "sujeto :  29\n",
            "sujeto :  30\n",
            "sujeto :  31\n",
            "sujeto :  33\n",
            "sujeto :  34\n",
            "sujeto :  35\n",
            "sujeto :  36\n",
            "sujeto :  37\n",
            "sujeto :  38\n",
            "sujeto :  39\n",
            "sujeto :  40\n",
            "sujeto :  41\n",
            "sujeto :  42\n",
            "sujeto :  43\n",
            "sujeto :  44\n",
            "sujeto :  45\n",
            "sujeto :  47\n",
            "sujeto :  48\n",
            "sujeto :  50\n",
            "sujeto :  51\n",
            "sujeto :  52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYEW5fgjDZKF"
      },
      "source": [
        "## PREDECIMOS EL SUJETO FALTANTE POR CADA MODELO Y GENERAMOS LA CURVA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Acc_subj_MTVAE=np.array(acc_subj_MTVAE)/100"
      ],
      "metadata": {
        "id": "LEsNzniUwasI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Ec(arr, target):\n",
        "    closest = 2000  # Inicializa con un valor muy grande\n",
        "    for num in arr:\n",
        "        diferencia = abs(num - target)\n",
        "        if diferencia < abs(closest - target):\n",
        "            closest = num\n",
        "    return closest"
      ],
      "metadata": {
        "id": "RiSX7kbMwcnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5Jhu5BgDdOn",
        "outputId": "79b16650-5ed0-4757-de84-ab427b9b4280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 59ms/step\n",
            "2/2 [==============================] - 0s 53ms/step\n",
            "2/2 [==============================] - 1s 58ms/step\n",
            "2/2 [==============================] - 1s 59ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c2bdd636d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 53ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c2bdd594f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 59ms/step\n",
            "2/2 [==============================] - 1s 56ms/step\n",
            "2/2 [==============================] - 1s 89ms/step\n",
            "2/2 [==============================] - 1s 97ms/step\n",
            "2/2 [==============================] - 1s 62ms/step\n",
            "2/2 [==============================] - 0s 50ms/step\n",
            "2/2 [==============================] - 1s 63ms/step\n",
            "2/2 [==============================] - 1s 57ms/step\n",
            "2/2 [==============================] - 1s 72ms/step\n",
            "2/2 [==============================] - 0s 49ms/step\n",
            "2/2 [==============================] - 1s 90ms/step\n",
            "2/2 [==============================] - 1s 102ms/step\n",
            "2/2 [==============================] - 0s 55ms/step\n",
            "2/2 [==============================] - 0s 49ms/step\n",
            "2/2 [==============================] - 0s 48ms/step\n",
            "2/2 [==============================] - 0s 46ms/step\n",
            "2/2 [==============================] - 1s 63ms/step\n",
            "2/2 [==============================] - 0s 44ms/step\n",
            "2/2 [==============================] - 0s 54ms/step\n",
            "2/2 [==============================] - 1s 92ms/step\n",
            "2/2 [==============================] - 1s 87ms/step\n",
            "2/2 [==============================] - 1s 67ms/step\n",
            "2/2 [==============================] - 1s 57ms/step\n",
            "2/2 [==============================] - 1s 58ms/step\n",
            "2/2 [==============================] - 0s 59ms/step\n",
            "2/2 [==============================] - 1s 58ms/step\n",
            "2/2 [==============================] - 0s 46ms/step\n",
            "2/2 [==============================] - 0s 44ms/step\n",
            "2/2 [==============================] - 1s 109ms/step\n",
            "2/2 [==============================] - 1s 50ms/step\n",
            "2/2 [==============================] - 0s 60ms/step\n",
            "2/2 [==============================] - 1s 55ms/step\n",
            "2/2 [==============================] - 0s 52ms/step\n",
            "2/2 [==============================] - 1s 49ms/step\n",
            "2/2 [==============================] - 1s 55ms/step\n",
            "2/2 [==============================] - 0s 53ms/step\n",
            "2/2 [==============================] - 1s 50ms/step\n",
            "2/2 [==============================] - 1s 108ms/step\n",
            "2/2 [==============================] - 1s 59ms/step\n",
            "2/2 [==============================] - 0s 54ms/step\n",
            "2/2 [==============================] - 0s 56ms/step\n",
            "2/2 [==============================] - 0s 49ms/step\n",
            "2/2 [==============================] - 0s 49ms/step\n",
            "2/2 [==============================] - 0s 49ms/step\n"
          ]
        }
      ],
      "source": [
        "prediccion_trial_1 = []\n",
        "prediccion_trial_media = []\n",
        "prediccion_trial_max = []\n",
        "prediccion_trial_min = []\n",
        "prediccion_cercano = []\n",
        "for i in range(len(y_data_total)):\n",
        "    ## ITERAMOS POR CADA SUJETO\n",
        "    x_suject = x_data_runs[:,1][i] ## OBTENEMOS LA INFORMACIÓN DEL SUJETO\n",
        "\n",
        "    ## CARGAMOS EL MODELO\n",
        "    MODEL = MTVAE_KL(Chans = 64, Samples = 256, dropoutRate = 0.5)\n",
        "    MODEL.compile(optimizer='adam',loss=['mse','mse'], metrics= ['mse'])\n",
        "    MODEL.load_weights('/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/model_run1_'+str(i)+'.h5')\n",
        "    ## HACEMOS LA PREDICCIÓN\n",
        "    data = MODEL.predict(x_suject)[1][:,0]\n",
        "    prediccion_trial_1.append(data[0])\n",
        "    prediccion_trial_media.append(np.mean(data))\n",
        "    prediccion_trial_max.append(np.max(data))\n",
        "    prediccion_cercano.append(Ec(data,Acc_subj_MTVAE[i]))\n",
        "    prediccion_trial_min.append(np.min(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "95tyES_xaIPf",
        "outputId": "2bf51fc0-150f-466a-a295-af03c56f6c62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Run 4 GENERAL')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(Acc_subj_MTVAE)\n",
        "plt.plot(prediccion_cercano)\n",
        "plt.title('Run 4 GENERAL')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculo de r y r2"
      ],
      "metadata": {
        "id": "epIuDz3cEZjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "rpg2t8QeEbAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r =  pearsonr(prediccion_cercano,Acc_subj_MTVAE)[0]\n",
        "r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmRMqLzEFLDY",
        "outputId": "30fc684c-90c3-4d89-8590-ae0914e1d372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9472973306076795"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_2  = r2_score(prediccion_cercano,Acc_subj_MTVAE)\n",
        "r_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv6vCrgQFQlQ",
        "outputId": "8c36885c-1703-4b7d-ad3c-cc69174ee7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8307318330777167"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAJAi3BefyhN",
        "outputId": "d7d4793e-d057-4776-d3e9-0d4185c49827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El coeficiente de determinación $R^2$ es: 0.8973694279562504\n"
          ]
        }
      ],
      "source": [
        "### R2\n",
        "# Calcular el coeficiente de determinación $R^2$.\n",
        "r2 = np.corrcoef(prediccion_cercano, Acc_subj_MTVAE)[0, 1]**2\n",
        "\n",
        "# Imprimir los resultados.\n",
        "print(\"El coeficiente de determinación $R^2$ es:\", r2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Supongamos que 'y_real' son los valores reales y 'y_pred' son las predicciones del modelo\n",
        "\n",
        "# Calcula la diferencia entre los valores reales y las predicciones\n",
        "diferencia = [r - p for r, p in zip(Acc_subj_MTVAE,prediccion_cercano)]\n",
        "\n",
        "# Realiza la prueba t de dos muestras relacionadas\n",
        "t_stat, p_value = ttest_rel(Acc_subj_MTVAE, prediccion_cercano)\n",
        "\n",
        "print(f'El valor p-valor es: {p_value}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfRbvdKjuqEG",
        "outputId": "64726599-ad9f-4abe-c647-99e4ea40c8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El valor p-valor es: 0.9587094912994513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ENTRENAMOS REGRESOR POR GRUPOS"
      ],
      "metadata": {
        "id": "Kt1B_Rec1Sth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "grupo 1"
      ],
      "metadata": {
        "id": "t3qU23v71XCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grupo_1 =sorted([41,24,5,30,27,37,9,13,23,14,3,44,52])\n",
        "grupo_2 = sorted([43,18,35,15,8,6,22,25,19,47,26,45,50,51])\n",
        "grupo_3 = sorted([48,29,33,28,4,21,20,7,34,40,42,31,12,16,1,39,11,17,10,2,36,38])\n",
        "\n",
        "len(grupo_1) + len(grupo_2) + len(grupo_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFekzY3T1YOE",
        "outputId": "b2a00235-25b8-472e-e042-8d5fb55b588e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### OBTENEMOS LOS DATOS UNICAMENTE DLE GRUPO\n",
        "y_data_grupo = []\n",
        "x_data_grupo = []\n",
        "\n",
        "for i in range(len(y_data_runs)):\n",
        "\n",
        "    if subjects[i] in grupo_3:\n",
        "       y_data_grupo.append(y_data_runs[:,4][i]) ## agregamos run 0\n",
        "       x_data_grupo.append(x_data_runs[:,4][i])\n",
        "\n",
        "y_data_grupo = np.array(y_data_grupo)\n",
        "x_data_grupo = np.array(x_data_grupo)\n",
        "print(y_data_grupo.shape)\n",
        "print(x_data_grupo.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-CpahSx1q3p",
        "outputId": "d3d85120-8bf3-4afc-aba5-058ec3bc25f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22, 39)\n",
            "(22, 39, 64, 256, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## COPIAMOS EL SET DE DATOS\n",
        "## LISTA PARA AGREGAR LA PREDICCIÓN DEL SUJETO\n",
        "for i in range(len(grupo_3)):\n",
        "\n",
        "  ### ELIMINAMOS EL SUJETO DEL SET DE DATOS PARA ENTRENAR EL MODELO\n",
        "\n",
        "  y_data_total_copy = np.copy(y_data_grupo)\n",
        "  x_data_total_copy = np.copy(x_data_grupo)\n",
        "  y_data_total_copy = np.delete(y_data_total_copy, i,axis=0)\n",
        "  x_data_total_copy = np.delete(x_data_total_copy, i,axis=0)\n",
        "  ### GENERAMOS EL SET DE DATOS DE ENTRENO Y VALIDACIÓN SIN TENER EN CUENTA EL SUJETO\n",
        "  y_train = y_data_total_copy[0]\n",
        "  x_train = x_data_total_copy[0]\n",
        "  print(y_train.shape,x_train.shape,y_data_total_copy.shape,x_data_total_copy.shape)\n",
        "  for a in range(1,len(y_data_total_copy)):\n",
        "      y_train = np.concatenate([y_train,y_data_total_copy[a]])\n",
        "      x_train = np.concatenate([x_train,x_data_total_copy[a]])\n",
        "  X_train_, X_test_, y_train_, y_test_ = train_test_split(x_train, y_train, test_size=0.20, random_state=42)\n",
        "  #### generamos el modelo\n",
        "  MODEL = MTVAE_KL(Chans = 64, Samples = 256, dropoutRate = 0.5)\n",
        "  ### COMPILAMOS EL MODELO\n",
        "  MODEL.compile(optimizer='adam',loss=['mse','mse'], metrics= ['mse'])\n",
        "  history = MODEL.fit(X_train_,[X_train_,y_train_],epochs= 60,verbose=0,validation_data=(X_test_, [X_test_,y_test_]),callbacks=[tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/model_group3_run4_'+str(i)+'.h5', save_best_only=True, monitor='val_out_activation_loss')])\n",
        "  ### GRAFICAMOS LAS CURVAS DE OVERFITTING\n",
        "  # loss = history.history['out_activation_mse']\n",
        "  # val_loss = history.history['val_out_activation_mse']\n",
        "  # epochs = range(1, len(loss) + 1)\n",
        "  # # break\n",
        "  # plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "  # plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  # plt.ylim([0, np.max(val_loss)])\n",
        "  # plt.title('Curvas de perdida MSE ' +str(subjects[i]) )\n",
        "  # save_file_path = os.path.join('/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/', 'REGRESOR_MI_run4' +str(i+1)  + '.png')\n",
        "  # plt.savefig(save_file_path)\n",
        "  # plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuLxmpUl1eYj",
        "outputId": "5dbf8a6e-cd8c-426e-cf37-970f212c884c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n",
            "(39,) (39, 64, 256, 1) (21, 39) (21, 39, 64, 256, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluamos rendimiento por grafica"
      ],
      "metadata": {
        "id": "GsW7QbNQ7WyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### OBTENEMOS LOS DATOS UNICAMENTE DLE GRUPO\n",
        "y_data_grupo = []\n",
        "x_data_grupo = []\n",
        "\n",
        "for i in range(len(y_data_runs)):\n",
        "\n",
        "    if subjects[i] in grupo_2:\n",
        "       y_data_grupo.append(y_data_runs[:,0][i]) ## agregamos run 0\n",
        "       x_data_grupo.append(x_data_runs[:,0][i])\n",
        "\n",
        "y_data_grupo = np.array(y_data_grupo)\n",
        "x_data_grupo = np.array(x_data_grupo)\n",
        "print(y_data_grupo.shape)\n",
        "print(x_data_grupo.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7tbtddk8Alx",
        "outputId": "8b7bd4b0-d50e-4ec8-b959-bda4269e2a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14, 40)\n",
            "(14, 40, 64, 256, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### sacamos curva de sujetos\n",
        "### OBTENEMOS LOS DATOS UNICAMENTE DLE GRUPO\n",
        "Acc_grupo = []\n",
        "\n",
        "for i in range(len(y_data_runs)):\n",
        "\n",
        "    if subjects[i] in grupo_2:\n",
        "       Acc_grupo.append(Acc_subj_MTVAE[i]) ## agregamos run 0\n",
        "\n",
        "Acc_grupo = np.array(Acc_grupo)"
      ],
      "metadata": {
        "id": "rDiPEH3u7YdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediccion_cercano = []\n",
        "for i in range(len(grupo_2)):\n",
        "    ## ITERAMOS POR CADA SUJETO\n",
        "    x_suject = x_data_grupo[i] ## OBTENEMOS LA INFORMACIÓN DEL SUJETO\n",
        "    ## CARGAMOS EL MODELO\n",
        "    MODEL = MTVAE_KL(Chans = 64, Samples = 256, dropoutRate = 0.5)\n",
        "    MODEL.compile(optimizer='adam',loss=['mse','mse'], metrics= ['mse'])\n",
        "    MODEL.load_weights('/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/model_group2_run0_'+str(i)+'.h5')\n",
        "    ## HACEMOS LA PREDICCIÓN\n",
        "    data = MODEL.predict(x_suject)[1][:,0]\n",
        "    prediccion_cercano.append(Ec(data,Acc_grupo[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upMNXmrn7r45",
        "outputId": "ab819052-a065-4930-c9d6-4b88c544c49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(Acc_grupo)\n",
        "plt.plot(prediccion_cercano)\n",
        "plt.title('Run 1 Grupo 2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "FcZq2UIt7oD4",
        "outputId": "dd94d7be-e5f3-4a85-fe59-34da0770f4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Run 1 Grupo 2')"
            ]
          },
          "metadata": {},
          "execution_count": 146
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### R2\n",
        "# Calcular el coeficiente de determinación $R^2$.\n",
        "r2 = np.corrcoef(prediccion_cercano, Acc_grupo)[0, 1]**2\n",
        "\n",
        "# Calcula el Mann-Whitney U test\n",
        "u_statistic, p_value = mannwhitneyu(Acc_grupo, prediccion_cercano)\n",
        "\n",
        "print(f\"P-Value: {p_value}\")\n",
        "# Imprimir los resultados.\n",
        "print(\"El coeficiente de determinación $R^2$ es:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndrBOwHv8UGt",
        "outputId": "1aced949-5594-4e86-bdb8-44d7a7a7229f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P-Value: 0.9450520886884962\n",
            "El coeficiente de determinación $R^2$ es: 0.9978558910400155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## REENTRENO REGRESOR TRANSFER LEARNING"
      ],
      "metadata": {
        "id": "BLHODJOaVAow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "cargamos los datos"
      ],
      "metadata": {
        "id": "NS5dNdEFVMt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_data_total_1 = pickle.load(open('/content/drive/MyDrive/EEG_DATA/GIGA_DATASET/y_regresor.pkl', 'rb'))\n",
        "x_data_total_1 = pickle.load(open('/content/drive/MyDrive/EEG_DATA/GIGA_DATASET/x_regresor.pkl', 'rb'))\n",
        "y_data_total_1 = np.array(y_data_total_1)\n",
        "x_data_total_1 = np.array(x_data_total_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hqSfvbuVGsr",
        "outputId": "baf0712c-0dbf-4bdb-f6f6-47871cffaf18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-148-2e04260f2c71>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y_data_total_1 = np.array(y_data_total_1)\n",
            "<ipython-input-148-2e04260f2c71>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_data_total_1 = np.array(x_data_total_1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_data_total_2 = pickle.load(open('/content/drive/MyDrive/EEG_DATA/MTVAE_SIN_SUJETO_DESPUES/y_regresor.pkl', 'rb'))\n",
        "x_data_total_2 = pickle.load(open('/content/drive/MyDrive/EEG_DATA/MTVAE_SIN_SUJETO_DESPUES/x_regresor.pkl', 'rb'))\n",
        "y_data_total_2 = np.array(y_data_total_2)\n",
        "x_data_total_2 = np.array(x_data_total_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7vLGztPVR8D",
        "outputId": "60cd41a1-a054-4a32-b387-9bbf43b1a3b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-149-527106ab94c9>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y_data_total_2 = np.array(y_data_total_2)\n",
            "<ipython-input-149-527106ab94c9>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_data_total_2 = np.array(x_data_total_2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data_total = []\n",
        "for i in range(0,len(y_data_total_1)):\n",
        "   x_data_total.append(np.concatenate([x_data_total_1[i],x_data_total_2[i]],axis=2))\n",
        "\n",
        "y_data_total = y_data_total_1\n",
        "x_data_total = np.array(x_data_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WVeyWztVdjg",
        "outputId": "292f434a-e072-458d-c3b6-757c682d8b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-150-61aeda96112e>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_data_total = np.array(x_data_total)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINIMOS EL MODELO"
      ],
      "metadata": {
        "id": "6gW3Q0GSVkoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_data_total.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_9xV1w_Ww-c",
        "outputId": "1a035ec3-7e5e-4640-c13f-6361f6a581f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49,)"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data_total[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OusiaOk_W12b",
        "outputId": "ed2341ba-470d-4616-8097-fda9f5c01ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(199, 64, 512, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### ELIMINAMOS EL SUJETO DEL SET DE DATOS PARA ENTRENAR EL MODELO\n",
        "\n",
        "y_data_total_copy = np.copy(y_data_total)\n",
        "x_data_total_copy = np.copy(x_data_total)\n",
        "### GENERAMOS EL SET DE DATOS DE ENTRENO Y VALIDACIÓN SIN TENER EN CUENTA EL SUJETO\n",
        "y_train = y_data_total_copy[0]\n",
        "x_train = x_data_total_copy[0]\n",
        "\n",
        "for a in range(1,len(y_data_total_copy)):\n",
        "    y_train = np.concatenate([y_train,y_data_total_copy[a]])\n",
        "    x_train = np.concatenate([x_train,x_data_total_copy[a]])\n",
        "X_train_, X_test_, y_train_, y_test_ = train_test_split(x_train, y_train, test_size=0.20, random_state=42)\n",
        "print(y_train_.shape,X_train_.shape,y_test_.shape,X_test_.shape)\n",
        "#### generamos el modelo\n",
        "MODEL = MTVAE_KL(Chans = 64, Samples = 448, dropoutRate = 0.5)\n",
        "### COMPILAMOS EL MODELO\n",
        "MODEL.compile(optimizer='adam',loss=['mse','mse'], metrics= ['mse'])\n",
        "history = MODEL.fit(X_train_[:,:,:448],[X_train_[:,:,:448],y_train_],epochs= 60,verbose=1,validation_data=(X_test_[:,:,:448], [X_test_[:,:,:448],y_test_]),callbacks=[tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/model_transfer_learning_regresor_'+'.h5', save_best_only=True, monitor='val_out_activation_loss')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnBGMRciVj2D",
        "outputId": "f5bf4b97-5a23-4f21-9605-c9c54b57c613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7802,) (7802, 64, 512, 1) (1951,) (1951, 64, 512, 1)\n",
            "Epoch 1/60\n",
            "244/244 [==============================] - 7s 15ms/step - loss: 1.1016 - conv2d_transpose_2192_loss: 1.0320 - out_activation_loss: 0.0566 - conv2d_transpose_2192_mse: 1.0320 - out_activation_mse: 0.0566 - val_loss: 1.0547 - val_conv2d_transpose_2192_loss: 1.0379 - val_out_activation_loss: 0.0165 - val_conv2d_transpose_2192_mse: 1.0379 - val_out_activation_mse: 0.0165\n",
            "Epoch 2/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0504 - conv2d_transpose_2192_loss: 1.0319 - out_activation_loss: 0.0167 - conv2d_transpose_2192_mse: 1.0319 - out_activation_mse: 0.0167 - val_loss: 1.0452 - val_conv2d_transpose_2192_loss: 1.0380 - val_out_activation_loss: 0.0072 - val_conv2d_transpose_2192_mse: 1.0380 - val_out_activation_mse: 0.0072\n",
            "Epoch 3/60\n",
            "244/244 [==============================] - 3s 12ms/step - loss: 1.0427 - conv2d_transpose_2192_loss: 1.0319 - out_activation_loss: 0.0106 - conv2d_transpose_2192_mse: 1.0319 - out_activation_mse: 0.0106 - val_loss: 1.0424 - val_conv2d_transpose_2192_loss: 1.0380 - val_out_activation_loss: 0.0044 - val_conv2d_transpose_2192_mse: 1.0380 - val_out_activation_mse: 0.0044\n",
            "Epoch 4/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0400 - conv2d_transpose_2192_loss: 1.0319 - out_activation_loss: 0.0080 - conv2d_transpose_2192_mse: 1.0319 - out_activation_mse: 0.0080 - val_loss: 1.0423 - val_conv2d_transpose_2192_loss: 1.0380 - val_out_activation_loss: 0.0043 - val_conv2d_transpose_2192_mse: 1.0380 - val_out_activation_mse: 0.0043\n",
            "Epoch 5/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0383 - conv2d_transpose_2192_loss: 1.0319 - out_activation_loss: 0.0064 - conv2d_transpose_2192_mse: 1.0319 - out_activation_mse: 0.0064 - val_loss: 1.0416 - val_conv2d_transpose_2192_loss: 1.0380 - val_out_activation_loss: 0.0036 - val_conv2d_transpose_2192_mse: 1.0380 - val_out_activation_mse: 0.0036\n",
            "Epoch 6/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0373 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0055 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0055 - val_loss: 1.0405 - val_conv2d_transpose_2192_loss: 1.0379 - val_out_activation_loss: 0.0026 - val_conv2d_transpose_2192_mse: 1.0379 - val_out_activation_mse: 0.0026\n",
            "Epoch 7/60\n",
            "244/244 [==============================] - 3s 12ms/step - loss: 1.0366 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0048 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0048 - val_loss: 1.0404 - val_conv2d_transpose_2192_loss: 1.0379 - val_out_activation_loss: 0.0025 - val_conv2d_transpose_2192_mse: 1.0379 - val_out_activation_mse: 0.0025\n",
            "Epoch 8/60\n",
            "244/244 [==============================] - 3s 12ms/step - loss: 1.0365 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0046 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0046 - val_loss: 1.0403 - val_conv2d_transpose_2192_loss: 1.0380 - val_out_activation_loss: 0.0023 - val_conv2d_transpose_2192_mse: 1.0380 - val_out_activation_mse: 0.0023\n",
            "Epoch 9/60\n",
            "244/244 [==============================] - 3s 12ms/step - loss: 1.0359 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0041 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0041 - val_loss: 1.0411 - val_conv2d_transpose_2192_loss: 1.0379 - val_out_activation_loss: 0.0032 - val_conv2d_transpose_2192_mse: 1.0379 - val_out_activation_mse: 0.0032\n",
            "Epoch 10/60\n",
            "244/244 [==============================] - 3s 12ms/step - loss: 1.0358 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0039 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0039 - val_loss: 1.0402 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0023 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0023\n",
            "Epoch 11/60\n",
            "244/244 [==============================] - 3s 12ms/step - loss: 1.0355 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0037 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0037 - val_loss: 1.0400 - val_conv2d_transpose_2192_loss: 1.0379 - val_out_activation_loss: 0.0021 - val_conv2d_transpose_2192_mse: 1.0379 - val_out_activation_mse: 0.0021\n",
            "Epoch 12/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0351 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0033 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0033 - val_loss: 1.0397 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0019 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0019\n",
            "Epoch 13/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0350 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0032 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0032 - val_loss: 1.0395 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0017 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0017\n",
            "Epoch 14/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0349 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0031 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0031 - val_loss: 1.0402 - val_conv2d_transpose_2192_loss: 1.0379 - val_out_activation_loss: 0.0023 - val_conv2d_transpose_2192_mse: 1.0379 - val_out_activation_mse: 0.0023\n",
            "Epoch 15/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0347 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0029 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0029 - val_loss: 1.0396 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0019 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0019\n",
            "Epoch 16/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0348 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0030 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0030 - val_loss: 1.0405 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0027 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0027\n",
            "Epoch 17/60\n",
            "244/244 [==============================] - 4s 14ms/step - loss: 1.0345 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0028 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0028 - val_loss: 1.0396 - val_conv2d_transpose_2192_loss: 1.0379 - val_out_activation_loss: 0.0017 - val_conv2d_transpose_2192_mse: 1.0379 - val_out_activation_mse: 0.0017\n",
            "Epoch 18/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0345 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0027 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0027 - val_loss: 1.0435 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0057 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0057\n",
            "Epoch 19/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0344 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0027 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0027 - val_loss: 1.0400 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0023 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0023\n",
            "Epoch 20/60\n",
            "244/244 [==============================] - 4s 15ms/step - loss: 1.0344 - conv2d_transpose_2192_loss: 1.0318 - out_activation_loss: 0.0026 - conv2d_transpose_2192_mse: 1.0318 - out_activation_mse: 0.0026 - val_loss: 1.0394 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0016 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0016\n",
            "Epoch 21/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0342 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0025 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0025 - val_loss: 1.0395 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0018 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0018\n",
            "Epoch 22/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0342 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0024 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0024 - val_loss: 1.0397 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0019 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0019\n",
            "Epoch 23/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0343 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0026 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0026 - val_loss: 1.0395 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0017 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0017\n",
            "Epoch 24/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0340 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0023 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0023 - val_loss: 1.0399 - val_conv2d_transpose_2192_loss: 1.0379 - val_out_activation_loss: 0.0021 - val_conv2d_transpose_2192_mse: 1.0379 - val_out_activation_mse: 0.0021\n",
            "Epoch 25/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0339 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0022 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0022 - val_loss: 1.0396 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0018 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0018\n",
            "Epoch 26/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0339 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0022 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0022 - val_loss: 1.0430 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0052 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0052\n",
            "Epoch 27/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0338 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0021 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0021 - val_loss: 1.0395 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0017 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0017\n",
            "Epoch 28/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0340 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0023 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0023 - val_loss: 1.0408 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0030 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0030\n",
            "Epoch 29/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0338 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0021 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0021 - val_loss: 1.0405 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0028 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0028\n",
            "Epoch 30/60\n",
            "244/244 [==============================] - 3s 14ms/step - loss: 1.0338 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0020 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0020 - val_loss: 1.0393 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0016 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0016\n",
            "Epoch 31/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0337 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0020 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0020 - val_loss: 1.0394 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0016 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0016\n",
            "Epoch 32/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0337 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0020 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0020 - val_loss: 1.0398 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0020 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0020\n",
            "Epoch 33/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0335 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0018 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0018 - val_loss: 1.0393 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0016 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0016\n",
            "Epoch 34/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0336 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0019 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0019 - val_loss: 1.0419 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0042 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0042\n",
            "Epoch 35/60\n",
            "244/244 [==============================] - 3s 14ms/step - loss: 1.0335 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0018 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0018 - val_loss: 1.0393 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0016 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0016\n",
            "Epoch 36/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0335 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0019 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0019 - val_loss: 1.0399 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0022 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0022\n",
            "Epoch 37/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0336 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0019 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0019 - val_loss: 1.0395 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0018 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0018\n",
            "Epoch 38/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0336 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0019 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0019 - val_loss: 1.0397 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0020 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0020\n",
            "Epoch 39/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0336 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0019 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0019 - val_loss: 1.0406 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0029 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0029\n",
            "Epoch 40/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0334 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0017 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0017 - val_loss: 1.0396 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0017 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0017\n",
            "Epoch 41/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0335 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0018 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0018 - val_loss: 1.0397 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0019 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0019\n",
            "Epoch 42/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0334 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0017 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0017 - val_loss: 1.0394 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0016 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0016\n",
            "Epoch 43/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0335 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0018 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0018 - val_loss: 1.0394 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0016 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0016\n",
            "Epoch 44/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0333 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0016 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0016 - val_loss: 1.0393 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0016 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0016\n",
            "Epoch 45/60\n",
            "244/244 [==============================] - 3s 14ms/step - loss: 1.0334 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0017 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0017 - val_loss: 1.0392 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0016 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0016\n",
            "Epoch 46/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0333 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0016 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0016 - val_loss: 1.0397 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0020 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0020\n",
            "Epoch 47/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0334 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0017 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0017 - val_loss: 1.0411 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0034 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0034\n",
            "Epoch 48/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0333 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0016 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0016 - val_loss: 1.0394 - val_conv2d_transpose_2192_loss: 1.0376 - val_out_activation_loss: 0.0018 - val_conv2d_transpose_2192_mse: 1.0376 - val_out_activation_mse: 0.0018\n",
            "Epoch 49/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0333 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0016 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0016 - val_loss: 1.0396 - val_conv2d_transpose_2192_loss: 1.0376 - val_out_activation_loss: 0.0019 - val_conv2d_transpose_2192_mse: 1.0376 - val_out_activation_mse: 0.0019\n",
            "Epoch 50/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0333 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0016 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0016 - val_loss: 1.0400 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0023 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0023\n",
            "Epoch 51/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0333 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0016 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0016 - val_loss: 1.0401 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0024 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0024\n",
            "Epoch 52/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0332 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0015 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0015 - val_loss: 1.0394 - val_conv2d_transpose_2192_loss: 1.0378 - val_out_activation_loss: 0.0016 - val_conv2d_transpose_2192_mse: 1.0378 - val_out_activation_mse: 0.0016\n",
            "Epoch 53/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0332 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0015 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0015 - val_loss: 1.0397 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0020 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0020\n",
            "Epoch 54/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0332 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0015 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0015 - val_loss: 1.0394 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0017 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0017\n",
            "Epoch 55/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0331 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0015 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0015 - val_loss: 1.0400 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0023 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0023\n",
            "Epoch 56/60\n",
            "244/244 [==============================] - 3s 14ms/step - loss: 1.0331 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0014 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0014 - val_loss: 1.0392 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0015 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0015\n",
            "Epoch 57/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0332 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0015 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0015 - val_loss: 1.0392 - val_conv2d_transpose_2192_loss: 1.0376 - val_out_activation_loss: 0.0016 - val_conv2d_transpose_2192_mse: 1.0376 - val_out_activation_mse: 0.0016\n",
            "Epoch 58/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0332 - conv2d_transpose_2192_loss: 1.0316 - out_activation_loss: 0.0015 - conv2d_transpose_2192_mse: 1.0316 - out_activation_mse: 0.0015 - val_loss: 1.0392 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0015 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0015\n",
            "Epoch 59/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0332 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0015 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0015 - val_loss: 1.0394 - val_conv2d_transpose_2192_loss: 1.0377 - val_out_activation_loss: 0.0017 - val_conv2d_transpose_2192_mse: 1.0377 - val_out_activation_mse: 0.0017\n",
            "Epoch 60/60\n",
            "244/244 [==============================] - 3s 11ms/step - loss: 1.0331 - conv2d_transpose_2192_loss: 1.0317 - out_activation_loss: 0.0014 - conv2d_transpose_2192_mse: 1.0317 - out_activation_mse: 0.0014 - val_loss: 1.0398 - val_conv2d_transpose_2192_loss: 1.0376 - val_out_activation_loss: 0.0021 - val_conv2d_transpose_2192_mse: 1.0376 - val_out_activation_mse: 0.0021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transfer Learning"
      ],
      "metadata": {
        "id": "kaZj57wJZZEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Cargamos los datos para el modelo de clasificación\n",
        "y_data_total = pickle.load(open('/content/drive/MyDrive/EEG_DATA/GIGA_DATASET/y_clasification.pkl', 'rb'))\n",
        "x_data_total = pickle.load(open('/content/drive/MyDrive/EEG_DATA/GIGA_DATASET/x_clasification.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "dgt8sT1nZbC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D,Conv2DTranspose\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Input, Flatten, Reshape\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "import tensorflow as tf\n",
        "\n",
        "class reparametrize(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        mean, log_var = inputs\n",
        "        eta = tf.random.normal(tf.shape(log_var))\n",
        "        sigma = tf.math.exp(log_var / 2)\n",
        "        return  mean + sigma * eta\n",
        "\n",
        "def MTVAE_CLASS(nb_classes, Chans = 22, Samples = 250, dropoutRate = 0.5, l1 = 0, l2 = 0,block1 = None):\n",
        "\n",
        "    filters      = (1,40)\n",
        "    strid        = (1,15)\n",
        "    pool         = (1,75)\n",
        "    bias_spatial = True\n",
        "    input_main   = Input((Chans, Samples, 1))\n",
        "\n",
        "\n",
        "    mu           = Dense(40,name='mu')(block1.output)\n",
        "    log_var      = Dense(40,name='log_var')(block1.output)\n",
        "    codings      = reparametrize(name='Code')([mu, log_var])\n",
        "\n",
        "    ConvC        = Conv2D(nb_classes, (1, block1.output.shape[2]),kernel_regularizer=l1_l2(l1=l1,l2=l2),kernel_constraint = max_norm(0.5, axis=(0,1,2)),name='ouput')(block1.output)\n",
        "    flat          = Flatten(name='output')(ConvC)\n",
        "    softmax      = Activation('softmax',name='out_activation')(flat)\n",
        "\n",
        "    block2       = Conv2DTranspose(40, pool,strides=strid,activation='tanh', kernel_regularizer=l1_l2(l1=l1,l2=l2),\n",
        "                          kernel_constraint = max_norm(2., axis=(0,1,2)))(codings)\n",
        "    block2       = Resizing(block2.shape[1], 205)(block2) ## ACT1.SHAPE\n",
        "    block2       = Conv2DTranspose(40, (Chans, 1), use_bias=bias_spatial, kernel_regularizer=l1_l2(l1=l1,l2=l2),\n",
        "                          kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
        "    block2       = Conv2DTranspose(1, filters,strides=(1,2),\n",
        "                                 input_shape=(Chans, Samples, 1),kernel_regularizer=l1_l2(l1=l1,l2=l2),\n",
        "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
        "\n",
        "    model = Model(inputs=block1.input, outputs=[block2,softmax])\n",
        "\n",
        "\n",
        "    var_flat      = Flatten()(log_var)\n",
        "    mu_flat       = Flatten()(mu)\n",
        "\n",
        "    KL = -0.5 * tf.keras.backend.sum( 1 + var_flat - tf.keras.backend.exp(var_flat) - tf.keras.backend.square(mu_flat),axis=-1)\n",
        "    model.add_loss(tf.keras.backend.mean(KL)/var_flat.shape[-1])#Chans*Samples)\n",
        "    return model"
      ],
      "metadata": {
        "id": "O4yG-Ol5aGoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "entrenamos"
      ],
      "metadata": {
        "id": "eyiTzTaiaQca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.prediction.Model_Control.Global_Class.Global_Class import ModelControl\n",
        "from src.prediction.Model_Control.Global_Class.Global_Class import DatasetControl"
      ],
      "metadata": {
        "id": "lqqG3TgIaM5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_mtvae_regresor = []\n",
        "#### OBTENEMOS LOS CALLBACKS NECESARIOS\n",
        "callbacks_names = {'early_stopping_train1':'early_stopping','checkpoint_train1':'checkpoint',\n",
        "                   'early_stopping_train2':'early_stopping','checkpoint_train2':'checkpoint',\n",
        "                   'early_stopping_train3':'early_stopping','checkpoint_train3':'checkpoint',\n",
        "                   'early_stopping_train4':'early_stopping','checkpoint_train4':'checkpoint'}"
      ],
      "metadata": {
        "id": "Ervb1eTGaR4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_data_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGvhvtILamXA",
        "outputId": "d59879ed-fad0-489d-86e7-eee4267770ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data_total[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6rHtnpGbMoq",
        "outputId": "cade5282-fe1f-4046-8bfc-f8d5514a59b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 64, 448, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(y_data_total)):\n",
        "\n",
        "    ####### SUJETO ###########\n",
        "    print(\"SUJETO : \",subjects[i])\n",
        "\n",
        "    #### CARGAMOS LOS DATOS DE ENTRENAMIENTO\n",
        "    x_train = x_data_total[i]\n",
        "    y_train = y_data_total[i]\n",
        "\n",
        "    #### CARGAMOS EL MODELO\n",
        "    ### CARGAMOS LA BASE DE DATOS BCI2A Y EEGNET\n",
        "    MODEL = MTVAE_KL(Chans = 64, Samples = 448, dropoutRate = 0.5)\n",
        "    ### COMPILAMOS EL MODELO\n",
        "    filepath = '/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/model_transfer_learning_regresor_'+'.h5'\n",
        "    MODEL.load_weights(filepath)\n",
        "    layer_name='bottleneck'\n",
        "    ENCODER = Model(inputs=MODEL.input,\n",
        "                                  outputs=MODEL.get_layer(layer_name).output)\n",
        "    print(\"ENCODER: \",ENCODER.summary())\n",
        "    ### CARGAMOS LA BASE DE DATOS BCI2A Y EEGNET\n",
        "    MODEL_CLASS = MTVAE_CLASS(Chans = 64, Samples = 448, dropoutRate = 0.5,nb_classes =2,block1 = ENCODER)\n",
        "\n",
        "    ### COMPILAMOS EL MODELO\n",
        "    # Congelar las capas del modelo original hasta la capa deseada (por ejemplo, 'mu')\n",
        "\n",
        "    # Imprimir la estructura del nuevo modelo después de congelar\n",
        "    MODEL_CLASS.compile(optimizer='adam',loss=['mse','categorical_crossentropy'],metrics = ['accuracy'])\n",
        "\n",
        "    ### ENTRENAMOS EL MODELO\n",
        "    validation = 'lawhern2018'\n",
        "      # ## '/content/drive/MyDrive/EEG_DATA/EEGNET_RESULTS/EEGNET_ALL_RUNS_BI_GIGA/'+\n",
        "    call_args = [\n",
        "          {'monitor':'val_out_activation_accuracy','patience':100,'min_delta':0.001,'mode':'max','verbose':1,'restore_best_weights':False},\n",
        "          {'filepath':'/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/'+'checkpoint1_'+str(subjects[i]),'save_format':'tf','monitor':'val_out_activation_accuracy','verbose':1,'save_best_only':True,'save_weights_only':True},\n",
        "          {'monitor':'val_out_activation_accuracy','patience':100,'min_delta':0.001,'mode':'max','verbose':1,'restore_best_weights':False},\n",
        "          {'filepath':'/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/'+'checkpoint2_'+str(subjects[i]),'save_format':'tf','monitor':'val_out_activation_accuracy','verbose':1,'save_best_only':True,'save_weights_only':True},\n",
        "          {'monitor':'val_out_activation_accuracy','patience':100,'min_delta':0.001,'mode':'max','verbose':1,'restore_best_weights':False},\n",
        "          {'filepath':'/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/'+'checkpoint3_'+str(subjects[i]),'save_format':'tf','monitor':'val_out_activation_accuracy','verbose':1,'save_best_only':True,'save_weights_only':True},\n",
        "          {'monitor':'val_out_activation_accuracy','patience':100,'min_delta':0.001,'mode':'max','verbose':1,'restore_best_weights':False},\n",
        "          {'filepath':'/content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/'+'checkpoint4_'+str(subjects[i]),'save_format':'tf','monitor':'val_out_activation_accuracy','verbose':1,'save_best_only':True,'save_weights_only':True},\n",
        "      ]\n",
        "\n",
        "    modelControl = ModelControl()\n",
        "    print(MODEL_CLASS.summary())\n",
        "\n",
        "    History,acc_model  = modelControl.train_model(Indice = 1,Model = MODEL_CLASS,X_train=x_train,Y_train=[x_train,y_train],x_val=x_train,y_val=[x_train,y_train],callbacks_names = callbacks_names,call_args =call_args,validation_mode = validation, batch_size =16,epochs = 800,verbose =0,autoencoder=True)\n",
        "\n",
        "    ### OBTENEMOS EL ACCURACY\n",
        "    print(\"ACCURACY PER SUBJECT: \",acc_model)\n",
        "    acc_mtvae_regresor.append(acc_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pztvUTl_aTv4",
        "outputId": "605d2a6e-9aae-4dd7-8a35-4d6b0c8fd428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.97778\n",
            "Epoch 101: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Fold 2 Classification accuracy: 1.000000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            " 100 101 102 103 104 105 106 107 108 109 135 136 137 138 139 155 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199] [ 90  91  92  93  94  95  96  97  98  99 110 111 112 113 114 115 116 117\n",
            " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 140\n",
            " 141 142 143 144 145 146 147 148 149 150 151 152 153 154]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.97778, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint3_43\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.97778\n",
            "Epoch 101: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Fold 3 Classification accuracy: 1.000000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 140 141 142 143 144 145 146 147 148\n",
            " 149 150 151 152 153 154] [135 136 137 138 139 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
            " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n",
            " 186 187 188 189 190 191 192 193 194 195 196 197 198 199]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.97778, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint4_43\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.97778\n",
            "Epoch 101: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Fold 4 Classification accuracy: 1.000000 \n",
            "ACCURACY PER SUBJECT:  94.5\n",
            "SUJETO :  44\n",
            "Model: \"model_888\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_836 (InputLayer)      [(None, 64, 448, 1)]      0         \n",
            "                                                                 \n",
            " Conv2D_1 (Conv2D)           (None, 64, 205, 40)       1640      \n",
            "                                                                 \n",
            " Conv2D_2 (Conv2D)           (None, 1, 205, 40)        102440    \n",
            "                                                                 \n",
            " batch_normalization_783 (B  (None, 1, 205, 40)        160       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " activation_783 (Activation  (None, 1, 205, 40)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " average_pooling2d_783 (Ave  (None, 1, 9, 40)          0         \n",
            " ragePooling2D)                                                  \n",
            "                                                                 \n",
            " bottleneck (Dropout)        (None, 1, 9, 40)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104240 (407.19 KB)\n",
            "Trainable params: 104160 (406.88 KB)\n",
            "Non-trainable params: 80 (320.00 Byte)\n",
            "_________________________________________________________________\n",
            "ENCODER:  None\n",
            "Model: \"model_889\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_836 (InputLayer)      [(None, 64, 448, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " Conv2D_1 (Conv2D)           (None, 64, 205, 40)          1640      ['input_836[0][0]']           \n",
            "                                                                                                  \n",
            " Conv2D_2 (Conv2D)           (None, 1, 205, 40)           102440    ['Conv2D_1[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_783 (B  (None, 1, 205, 40)           160       ['Conv2D_2[0][0]']            \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_783 (Activation  (None, 1, 205, 40)           0         ['batch_normalization_783[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_783 (Ave  (None, 1, 9, 40)             0         ['activation_783[0][0]']      \n",
            " ragePooling2D)                                                                                   \n",
            "                                                                                                  \n",
            " bottleneck (Dropout)        (None, 1, 9, 40)             0         ['average_pooling2d_783[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " mu (Dense)                  (None, 1, 9, 40)             1640      ['bottleneck[0][0]']          \n",
            "                                                                                                  \n",
            " log_var (Dense)             (None, 1, 9, 40)             1640      ['bottleneck[0][0]']          \n",
            "                                                                                                  \n",
            " Code (reparametrize)        (None, 1, 9, 40)             0         ['mu[0][0]',                  \n",
            "                                                                     'log_var[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_2508 (Con  (None, 1, 195, 40)           120040    ['Code[0][0]']                \n",
            " v2DTranspose)                                                                                    \n",
            "                                                                                                  \n",
            " resizing_836 (Resizing)     (None, 1, 205, 40)           0         ['conv2d_transpose_2508[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " ouput (Conv2D)              (None, 1, 1, 2)              722       ['bottleneck[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_2509 (Con  (None, 64, 205, 40)          102440    ['resizing_836[0][0]']        \n",
            " v2DTranspose)                                                                                    \n",
            "                                                                                                  \n",
            " output (Flatten)            (None, 2)                    0         ['ouput[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose_2510 (Con  (None, 64, 448, 1)           1601      ['conv2d_transpose_2509[0][0]'\n",
            " v2DTranspose)                                                      ]                             \n",
            "                                                                                                  \n",
            " out_activation (Activation  (None, 2)                    0         ['output[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_1672 (Flatten)      (None, 360)                  0         ['log_var[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_836 (  (None, 360)                  0         ['flatten_1672[0][0]']        \n",
            " TFOpLambda)                                                                                      \n",
            "                                                                                                  \n",
            " tf.math.exp_836 (TFOpLambd  (None, 360)                  0         ['flatten_1672[0][0]']        \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " flatten_1673 (Flatten)      (None, 360)                  0         ['mu[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.math.subtract_1672 (TFO  (None, 360)                  0         ['tf.__operators__.add_836[0][\n",
            " pLambda)                                                           0]',                          \n",
            "                                                                     'tf.math.exp_836[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.square_836 (TFOpLa  (None, 360)                  0         ['flatten_1673[0][0]']        \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.subtract_1673 (TFO  (None, 360)                  0         ['tf.math.subtract_1672[0][0]'\n",
            " pLambda)                                                           , 'tf.math.square_836[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_836 (TF  (None,)                      0         ['tf.math.subtract_1673[0][0]'\n",
            " OpLambda)                                                          ]                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_836 (TFOp  (None,)                      0         ['tf.math.reduce_sum_836[0][0]\n",
            " Lambda)                                                            ']                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_836 (T  ()                           0         ['tf.math.multiply_836[0][0]']\n",
            " FOpLambda)                                                                                       \n",
            "                                                                                                  \n",
            " tf.math.truediv_836 (TFOpL  ()                           0         ['tf.math.reduce_mean_836[0][0\n",
            " ambda)                                                             ]']                           \n",
            "                                                                                                  \n",
            " add_loss_836 (AddLoss)      ()                           0         ['tf.math.truediv_836[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 332323 (1.27 MB)\n",
            "Trainable params: 332243 (1.27 MB)\n",
            "Non-trainable params: 80 (320.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "data genial: \n",
            "data:  [ 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  65  66  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85\n",
            "  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103\n",
            " 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121\n",
            " 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
            " 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 60 61 62\n",
            " 63 64]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.44444, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_44\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy improved from 0.44444 to 0.64444, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_44\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy did not improve from 0.64444\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.64444\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.64444\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.64444\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy improved from 0.64444 to 0.88889, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_44\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy improved from 0.88889 to 0.91111, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_44\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.91111\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy improved from 0.91111 to 0.93333, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_44\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy improved from 0.93333 to 0.95556, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_44\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy improved from 0.95556 to 0.97778, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_44\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 102: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 103: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 104: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 105: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 106: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 107: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 108: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 109: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 110: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 111: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 112: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 113: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 114: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 115: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 116: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 117: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 118: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 119: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 120: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 121: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 122: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 123: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 124: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 125: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 126: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 127: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 128: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 129: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 130: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 131: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 132: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 133: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 134: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 135: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 136: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 137: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 138: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 139: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 140: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 141: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 142: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 143: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 144: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 145: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 146: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 147: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 148: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 149: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 150: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 151: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 152: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 153: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 154: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 155: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 156: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 157: val_out_activation_accuracy did not improve from 0.97778\n",
            "Epoch 157: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Fold 1 Classification accuracy: 0.840000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  60  61  62  63  64  90  91  92  93\n",
            "  94  95  96  97  98  99 110 111 112 113 114 115 116 117 118 119 120 121\n",
            " 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
            " 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199] [ 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  65  66  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85\n",
            "  86  87  88  89 100 101 102 103 104 105 106 107 108 109]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.86667, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint2_44\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy did not improve from 0.86667\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy improved from 0.86667 to 0.88889, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint2_44\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 102: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 103: val_out_activation_accuracy did not improve from 0.88889\n",
            "Epoch 103: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Fold 2 Classification accuracy: 1.000000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            " 100 101 102 103 104 105 106 107 108 109 135 136 137 138 139 155 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199] [ 90  91  92  93  94  95  96  97  98  99 110 111 112 113 114 115 116 117\n",
            " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 140\n",
            " 141 142 143 144 145 146 147 148 149 150 151 152 153 154]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.88889, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint3_44\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy improved from 0.88889 to 0.93333, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint3_44\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy improved from 0.93333 to 0.95556, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint3_44\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 102: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 103: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 104: val_out_activation_accuracy did not improve from 0.95556\n",
            "Epoch 104: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Fold 3 Classification accuracy: 0.980000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 140 141 142 143 144 145 146 147 148\n",
            " 149 150 151 152 153 154] [135 136 137 138 139 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
            " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n",
            " 186 187 188 189 190 191 192 193 194 195 196 197 198 199]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.97778, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint4_44\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.97778\n",
            "Epoch 101: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Fold 4 Classification accuracy: 0.940000 \n",
            "ACCURACY PER SUBJECT:  94.0\n",
            "SUJETO :  45\n",
            "Model: \"model_891\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_838 (InputLayer)      [(None, 64, 448, 1)]      0         \n",
            "                                                                 \n",
            " Conv2D_1 (Conv2D)           (None, 64, 205, 40)       1640      \n",
            "                                                                 \n",
            " Conv2D_2 (Conv2D)           (None, 1, 205, 40)        102440    \n",
            "                                                                 \n",
            " batch_normalization_784 (B  (None, 1, 205, 40)        160       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " activation_784 (Activation  (None, 1, 205, 40)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " average_pooling2d_784 (Ave  (None, 1, 9, 40)          0         \n",
            " ragePooling2D)                                                  \n",
            "                                                                 \n",
            " bottleneck (Dropout)        (None, 1, 9, 40)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104240 (407.19 KB)\n",
            "Trainable params: 104160 (406.88 KB)\n",
            "Non-trainable params: 80 (320.00 Byte)\n",
            "_________________________________________________________________\n",
            "ENCODER:  None\n",
            "Model: \"model_892\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_838 (InputLayer)      [(None, 64, 448, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " Conv2D_1 (Conv2D)           (None, 64, 205, 40)          1640      ['input_838[0][0]']           \n",
            "                                                                                                  \n",
            " Conv2D_2 (Conv2D)           (None, 1, 205, 40)           102440    ['Conv2D_1[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_784 (B  (None, 1, 205, 40)           160       ['Conv2D_2[0][0]']            \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_784 (Activation  (None, 1, 205, 40)           0         ['batch_normalization_784[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_784 (Ave  (None, 1, 9, 40)             0         ['activation_784[0][0]']      \n",
            " ragePooling2D)                                                                                   \n",
            "                                                                                                  \n",
            " bottleneck (Dropout)        (None, 1, 9, 40)             0         ['average_pooling2d_784[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " mu (Dense)                  (None, 1, 9, 40)             1640      ['bottleneck[0][0]']          \n",
            "                                                                                                  \n",
            " log_var (Dense)             (None, 1, 9, 40)             1640      ['bottleneck[0][0]']          \n",
            "                                                                                                  \n",
            " Code (reparametrize)        (None, 1, 9, 40)             0         ['mu[0][0]',                  \n",
            "                                                                     'log_var[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_2514 (Con  (None, 1, 195, 40)           120040    ['Code[0][0]']                \n",
            " v2DTranspose)                                                                                    \n",
            "                                                                                                  \n",
            " resizing_838 (Resizing)     (None, 1, 205, 40)           0         ['conv2d_transpose_2514[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " ouput (Conv2D)              (None, 1, 1, 2)              722       ['bottleneck[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_2515 (Con  (None, 64, 205, 40)          102440    ['resizing_838[0][0]']        \n",
            " v2DTranspose)                                                                                    \n",
            "                                                                                                  \n",
            " output (Flatten)            (None, 2)                    0         ['ouput[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose_2516 (Con  (None, 64, 448, 1)           1601      ['conv2d_transpose_2515[0][0]'\n",
            " v2DTranspose)                                                      ]                             \n",
            "                                                                                                  \n",
            " out_activation (Activation  (None, 2)                    0         ['output[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_1676 (Flatten)      (None, 360)                  0         ['log_var[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_838 (  (None, 360)                  0         ['flatten_1676[0][0]']        \n",
            " TFOpLambda)                                                                                      \n",
            "                                                                                                  \n",
            " tf.math.exp_838 (TFOpLambd  (None, 360)                  0         ['flatten_1676[0][0]']        \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " flatten_1677 (Flatten)      (None, 360)                  0         ['mu[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.math.subtract_1676 (TFO  (None, 360)                  0         ['tf.__operators__.add_838[0][\n",
            " pLambda)                                                           0]',                          \n",
            "                                                                     'tf.math.exp_838[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.square_838 (TFOpLa  (None, 360)                  0         ['flatten_1677[0][0]']        \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.subtract_1677 (TFO  (None, 360)                  0         ['tf.math.subtract_1676[0][0]'\n",
            " pLambda)                                                           , 'tf.math.square_838[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_838 (TF  (None,)                      0         ['tf.math.subtract_1677[0][0]'\n",
            " OpLambda)                                                          ]                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_838 (TFOp  (None,)                      0         ['tf.math.reduce_sum_838[0][0]\n",
            " Lambda)                                                            ']                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_838 (T  ()                           0         ['tf.math.multiply_838[0][0]']\n",
            " FOpLambda)                                                                                       \n",
            "                                                                                                  \n",
            " tf.math.truediv_838 (TFOpL  ()                           0         ['tf.math.reduce_mean_838[0][0\n",
            " ambda)                                                             ]']                           \n",
            "                                                                                                  \n",
            " add_loss_838 (AddLoss)      ()                           0         ['tf.math.truediv_838[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 332323 (1.27 MB)\n",
            "Trainable params: 332243 (1.27 MB)\n",
            "Non-trainable params: 80 (320.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "data genial: \n",
            "data:  [ 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  65  66  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85\n",
            "  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103\n",
            " 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121\n",
            " 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
            " 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 60 61 62\n",
            " 63 64]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.42222, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_45\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy improved from 0.42222 to 0.46667, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_45\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy improved from 0.46667 to 0.51111, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_45\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy improved from 0.51111 to 0.53333, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_45\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.53333\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.53333\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy improved from 0.53333 to 0.57778, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_45\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.57778\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.57778\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.57778\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy improved from 0.57778 to 0.64444, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_45\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.64444\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.64444\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.64444\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy improved from 0.64444 to 0.66667, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_45\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy improved from 0.66667 to 0.68889, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_45\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 102: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 103: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 104: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 105: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 106: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 107: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 108: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 109: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 110: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 111: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 112: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 113: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 114: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 115: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 116: val_out_activation_accuracy did not improve from 0.68889\n",
            "Epoch 116: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Fold 1 Classification accuracy: 0.760000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  60  61  62  63  64  90  91  92  93\n",
            "  94  95  96  97  98  99 110 111 112 113 114 115 116 117 118 119 120 121\n",
            " 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
            " 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199] [ 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  65  66  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85\n",
            "  86  87  88  89 100 101 102 103 104 105 106 107 108 109]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.77778, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint2_45\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.77778\n",
            "Epoch 101: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Fold 2 Classification accuracy: 0.840000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            " 100 101 102 103 104 105 106 107 108 109 135 136 137 138 139 155 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199] [ 90  91  92  93  94  95  96  97  98  99 110 111 112 113 114 115 116 117\n",
            " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 140\n",
            " 141 142 143 144 145 146 147 148 149 150 151 152 153 154]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.88889, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint3_45\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.88889\n",
            "Epoch 101: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Fold 3 Classification accuracy: 0.900000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 140 141 142 143 144 145 146 147 148\n",
            " 149 150 151 152 153 154] [135 136 137 138 139 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
            " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n",
            " 186 187 188 189 190 191 192 193 194 195 196 197 198 199]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.93333, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint4_45\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy improved from 0.93333 to 0.95556, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint4_45\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 102: val_out_activation_accuracy did not improve from 0.95556\n",
            "Epoch 102: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Fold 4 Classification accuracy: 0.860000 \n",
            "ACCURACY PER SUBJECT:  84.0\n",
            "SUJETO :  47\n",
            "Model: \"model_894\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_840 (InputLayer)      [(None, 64, 448, 1)]      0         \n",
            "                                                                 \n",
            " Conv2D_1 (Conv2D)           (None, 64, 205, 40)       1640      \n",
            "                                                                 \n",
            " Conv2D_2 (Conv2D)           (None, 1, 205, 40)        102440    \n",
            "                                                                 \n",
            " batch_normalization_785 (B  (None, 1, 205, 40)        160       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " activation_785 (Activation  (None, 1, 205, 40)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " average_pooling2d_785 (Ave  (None, 1, 9, 40)          0         \n",
            " ragePooling2D)                                                  \n",
            "                                                                 \n",
            " bottleneck (Dropout)        (None, 1, 9, 40)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104240 (407.19 KB)\n",
            "Trainable params: 104160 (406.88 KB)\n",
            "Non-trainable params: 80 (320.00 Byte)\n",
            "_________________________________________________________________\n",
            "ENCODER:  None\n",
            "Model: \"model_895\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_840 (InputLayer)      [(None, 64, 448, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " Conv2D_1 (Conv2D)           (None, 64, 205, 40)          1640      ['input_840[0][0]']           \n",
            "                                                                                                  \n",
            " Conv2D_2 (Conv2D)           (None, 1, 205, 40)           102440    ['Conv2D_1[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_785 (B  (None, 1, 205, 40)           160       ['Conv2D_2[0][0]']            \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_785 (Activation  (None, 1, 205, 40)           0         ['batch_normalization_785[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_785 (Ave  (None, 1, 9, 40)             0         ['activation_785[0][0]']      \n",
            " ragePooling2D)                                                                                   \n",
            "                                                                                                  \n",
            " bottleneck (Dropout)        (None, 1, 9, 40)             0         ['average_pooling2d_785[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " mu (Dense)                  (None, 1, 9, 40)             1640      ['bottleneck[0][0]']          \n",
            "                                                                                                  \n",
            " log_var (Dense)             (None, 1, 9, 40)             1640      ['bottleneck[0][0]']          \n",
            "                                                                                                  \n",
            " Code (reparametrize)        (None, 1, 9, 40)             0         ['mu[0][0]',                  \n",
            "                                                                     'log_var[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_2520 (Con  (None, 1, 195, 40)           120040    ['Code[0][0]']                \n",
            " v2DTranspose)                                                                                    \n",
            "                                                                                                  \n",
            " resizing_840 (Resizing)     (None, 1, 205, 40)           0         ['conv2d_transpose_2520[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " ouput (Conv2D)              (None, 1, 1, 2)              722       ['bottleneck[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_2521 (Con  (None, 64, 205, 40)          102440    ['resizing_840[0][0]']        \n",
            " v2DTranspose)                                                                                    \n",
            "                                                                                                  \n",
            " output (Flatten)            (None, 2)                    0         ['ouput[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose_2522 (Con  (None, 64, 448, 1)           1601      ['conv2d_transpose_2521[0][0]'\n",
            " v2DTranspose)                                                      ]                             \n",
            "                                                                                                  \n",
            " out_activation (Activation  (None, 2)                    0         ['output[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_1680 (Flatten)      (None, 360)                  0         ['log_var[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_840 (  (None, 360)                  0         ['flatten_1680[0][0]']        \n",
            " TFOpLambda)                                                                                      \n",
            "                                                                                                  \n",
            " tf.math.exp_840 (TFOpLambd  (None, 360)                  0         ['flatten_1680[0][0]']        \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " flatten_1681 (Flatten)      (None, 360)                  0         ['mu[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.math.subtract_1680 (TFO  (None, 360)                  0         ['tf.__operators__.add_840[0][\n",
            " pLambda)                                                           0]',                          \n",
            "                                                                     'tf.math.exp_840[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.square_840 (TFOpLa  (None, 360)                  0         ['flatten_1681[0][0]']        \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.subtract_1681 (TFO  (None, 360)                  0         ['tf.math.subtract_1680[0][0]'\n",
            " pLambda)                                                           , 'tf.math.square_840[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_840 (TF  (None,)                      0         ['tf.math.subtract_1681[0][0]'\n",
            " OpLambda)                                                          ]                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_840 (TFOp  (None,)                      0         ['tf.math.reduce_sum_840[0][0]\n",
            " Lambda)                                                            ']                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_840 (T  ()                           0         ['tf.math.multiply_840[0][0]']\n",
            " FOpLambda)                                                                                       \n",
            "                                                                                                  \n",
            " tf.math.truediv_840 (TFOpL  ()                           0         ['tf.math.reduce_mean_840[0][0\n",
            " ambda)                                                             ]']                           \n",
            "                                                                                                  \n",
            " add_loss_840 (AddLoss)      ()                           0         ['tf.math.truediv_840[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 332323 (1.27 MB)\n",
            "Trainable params: 332243 (1.27 MB)\n",
            "Non-trainable params: 80 (320.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "data genial: \n",
            "data:  [ 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  65  66  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85\n",
            "  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103\n",
            " 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121\n",
            " 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
            " 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 60 61 62\n",
            " 63 64]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.46667, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_47\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy improved from 0.46667 to 0.48889, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_47\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy improved from 0.48889 to 0.60000, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_47\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy improved from 0.60000 to 0.71111, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_47\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.71111\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.71111\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.71111\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.71111\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.71111\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.71111\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.71111\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.71111\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.71111\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy improved from 0.71111 to 0.75556, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_47\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.75556\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy improved from 0.75556 to 0.77778, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_47\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.77778\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy improved from 0.77778 to 0.80000, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_47\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy improved from 0.80000 to 0.82222, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_47\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy improved from 0.82222 to 0.84444, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_47\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy improved from 0.84444 to 0.88889, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_47\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 102: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 103: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 104: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 105: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 106: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 107: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 108: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 109: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 110: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 111: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 112: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 113: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 114: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 115: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 116: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 117: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 118: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 119: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 120: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 121: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 122: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 123: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 124: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 125: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 126: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 127: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 128: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 129: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 130: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 131: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 132: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 133: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 134: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 135: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 136: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 137: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 138: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 139: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 140: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 141: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 142: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 143: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 144: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 145: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 146: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 147: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 148: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 149: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 150: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 151: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 152: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 153: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 154: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 155: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 156: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 157: val_out_activation_accuracy did not improve from 0.88889\n",
            "Epoch 157: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Fold 1 Classification accuracy: 0.720000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  60  61  62  63  64  90  91  92  93\n",
            "  94  95  96  97  98  99 110 111 112 113 114 115 116 117 118 119 120 121\n",
            " 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
            " 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199] [ 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  65  66  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85\n",
            "  86  87  88  89 100 101 102 103 104 105 106 107 108 109]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.75556, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint2_47\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy improved from 0.75556 to 0.84444, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint2_47\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy improved from 0.84444 to 0.88889, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint2_47\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 102: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 103: val_out_activation_accuracy did not improve from 0.88889\n",
            "Epoch 103: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Fold 2 Classification accuracy: 0.740000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            " 100 101 102 103 104 105 106 107 108 109 135 136 137 138 139 155 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199] [ 90  91  92  93  94  95  96  97  98  99 110 111 112 113 114 115 116 117\n",
            " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 140\n",
            " 141 142 143 144 145 146 147 148 149 150 151 152 153 154]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.80000, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint3_47\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy improved from 0.80000 to 0.82222, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint3_47\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 102: val_out_activation_accuracy did not improve from 0.82222\n",
            "Epoch 102: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Fold 3 Classification accuracy: 1.000000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 140 141 142 143 144 145 146 147 148\n",
            " 149 150 151 152 153 154] [135 136 137 138 139 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
            " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n",
            " 186 187 188 189 190 191 192 193 194 195 196 197 198 199]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.82222, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint4_47\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy improved from 0.82222 to 0.84444, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint4_47\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy improved from 0.84444 to 0.88889, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint4_47\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 102: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 103: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 104: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 105: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 106: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 107: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 108: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 109: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 110: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 111: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 112: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 113: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 114: val_out_activation_accuracy did not improve from 0.88889\n",
            "\n",
            "Epoch 115: val_out_activation_accuracy did not improve from 0.88889\n",
            "Epoch 115: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Fold 4 Classification accuracy: 0.760000 \n",
            "ACCURACY PER SUBJECT:  80.5\n",
            "SUJETO :  48\n",
            "Model: \"model_897\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_842 (InputLayer)      [(None, 64, 448, 1)]      0         \n",
            "                                                                 \n",
            " Conv2D_1 (Conv2D)           (None, 64, 205, 40)       1640      \n",
            "                                                                 \n",
            " Conv2D_2 (Conv2D)           (None, 1, 205, 40)        102440    \n",
            "                                                                 \n",
            " batch_normalization_786 (B  (None, 1, 205, 40)        160       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " activation_786 (Activation  (None, 1, 205, 40)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " average_pooling2d_786 (Ave  (None, 1, 9, 40)          0         \n",
            " ragePooling2D)                                                  \n",
            "                                                                 \n",
            " bottleneck (Dropout)        (None, 1, 9, 40)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104240 (407.19 KB)\n",
            "Trainable params: 104160 (406.88 KB)\n",
            "Non-trainable params: 80 (320.00 Byte)\n",
            "_________________________________________________________________\n",
            "ENCODER:  None\n",
            "Model: \"model_898\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_842 (InputLayer)      [(None, 64, 448, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " Conv2D_1 (Conv2D)           (None, 64, 205, 40)          1640      ['input_842[0][0]']           \n",
            "                                                                                                  \n",
            " Conv2D_2 (Conv2D)           (None, 1, 205, 40)           102440    ['Conv2D_1[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_786 (B  (None, 1, 205, 40)           160       ['Conv2D_2[0][0]']            \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_786 (Activation  (None, 1, 205, 40)           0         ['batch_normalization_786[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_786 (Ave  (None, 1, 9, 40)             0         ['activation_786[0][0]']      \n",
            " ragePooling2D)                                                                                   \n",
            "                                                                                                  \n",
            " bottleneck (Dropout)        (None, 1, 9, 40)             0         ['average_pooling2d_786[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " mu (Dense)                  (None, 1, 9, 40)             1640      ['bottleneck[0][0]']          \n",
            "                                                                                                  \n",
            " log_var (Dense)             (None, 1, 9, 40)             1640      ['bottleneck[0][0]']          \n",
            "                                                                                                  \n",
            " Code (reparametrize)        (None, 1, 9, 40)             0         ['mu[0][0]',                  \n",
            "                                                                     'log_var[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_2526 (Con  (None, 1, 195, 40)           120040    ['Code[0][0]']                \n",
            " v2DTranspose)                                                                                    \n",
            "                                                                                                  \n",
            " resizing_842 (Resizing)     (None, 1, 205, 40)           0         ['conv2d_transpose_2526[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " ouput (Conv2D)              (None, 1, 1, 2)              722       ['bottleneck[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_2527 (Con  (None, 64, 205, 40)          102440    ['resizing_842[0][0]']        \n",
            " v2DTranspose)                                                                                    \n",
            "                                                                                                  \n",
            " output (Flatten)            (None, 2)                    0         ['ouput[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose_2528 (Con  (None, 64, 448, 1)           1601      ['conv2d_transpose_2527[0][0]'\n",
            " v2DTranspose)                                                      ]                             \n",
            "                                                                                                  \n",
            " out_activation (Activation  (None, 2)                    0         ['output[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_1684 (Flatten)      (None, 360)                  0         ['log_var[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_842 (  (None, 360)                  0         ['flatten_1684[0][0]']        \n",
            " TFOpLambda)                                                                                      \n",
            "                                                                                                  \n",
            " tf.math.exp_842 (TFOpLambd  (None, 360)                  0         ['flatten_1684[0][0]']        \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " flatten_1685 (Flatten)      (None, 360)                  0         ['mu[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.math.subtract_1684 (TFO  (None, 360)                  0         ['tf.__operators__.add_842[0][\n",
            " pLambda)                                                           0]',                          \n",
            "                                                                     'tf.math.exp_842[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.square_842 (TFOpLa  (None, 360)                  0         ['flatten_1685[0][0]']        \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.subtract_1685 (TFO  (None, 360)                  0         ['tf.math.subtract_1684[0][0]'\n",
            " pLambda)                                                           , 'tf.math.square_842[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_842 (TF  (None,)                      0         ['tf.math.subtract_1685[0][0]'\n",
            " OpLambda)                                                          ]                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_842 (TFOp  (None,)                      0         ['tf.math.reduce_sum_842[0][0]\n",
            " Lambda)                                                            ']                            \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_842 (T  ()                           0         ['tf.math.multiply_842[0][0]']\n",
            " FOpLambda)                                                                                       \n",
            "                                                                                                  \n",
            " tf.math.truediv_842 (TFOpL  ()                           0         ['tf.math.reduce_mean_842[0][0\n",
            " ambda)                                                             ]']                           \n",
            "                                                                                                  \n",
            " add_loss_842 (AddLoss)      ()                           0         ['tf.math.truediv_842[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 332323 (1.27 MB)\n",
            "Trainable params: 332243 (1.27 MB)\n",
            "Non-trainable params: 80 (320.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "data genial: \n",
            "data:  [ 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  65  66  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85\n",
            "  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103\n",
            " 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121\n",
            " 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
            " 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 60 61 62\n",
            " 63 64]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.55556, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_48\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy did not improve from 0.55556\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy improved from 0.55556 to 0.60000, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_48\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.60000\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.60000\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy improved from 0.60000 to 0.68889, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_48\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy improved from 0.68889 to 0.71111, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_48\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy improved from 0.71111 to 0.75556, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_48\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy improved from 0.75556 to 0.77778, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_48\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy improved from 0.77778 to 0.80000, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_48\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy improved from 0.80000 to 0.84444, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_48\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy improved from 0.84444 to 0.86667, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_48\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.86667\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.86667\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy improved from 0.86667 to 0.91111, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_48\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.91111\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy improved from 0.91111 to 0.95556, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_48\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy improved from 0.95556 to 0.97778, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint1_48\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 102: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 103: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 104: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 105: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 106: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 107: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 108: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 109: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 110: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 111: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 112: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 113: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 114: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 115: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 116: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 117: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 118: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 119: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 120: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 121: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 122: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 123: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 124: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 125: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 126: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 127: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 128: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 129: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 130: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 131: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 132: val_out_activation_accuracy did not improve from 0.97778\n",
            "Epoch 132: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Fold 1 Classification accuracy: 0.900000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  60  61  62  63  64  90  91  92  93\n",
            "  94  95  96  97  98  99 110 111 112 113 114 115 116 117 118 119 120 121\n",
            " 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
            " 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199] [ 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  65  66  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85\n",
            "  86  87  88  89 100 101 102 103 104 105 106 107 108 109]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.84444, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint2_48\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy improved from 0.84444 to 0.95556, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint2_48\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy improved from 0.95556 to 0.97778, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint2_48\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 102: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 103: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 104: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 105: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 106: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 107: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 108: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 109: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 110: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 111: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 112: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 113: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 114: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 115: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 116: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 117: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 118: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 119: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 120: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 121: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 122: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 123: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 124: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 125: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 126: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 127: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 128: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 129: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 130: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 131: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 132: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 133: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 134: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 135: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 136: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 137: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 138: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 139: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 140: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 141: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 142: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 143: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 144: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 145: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 146: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 147: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 148: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 149: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 150: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 151: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 152: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 153: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 154: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 155: val_out_activation_accuracy did not improve from 0.97778\n",
            "Epoch 155: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Fold 2 Classification accuracy: 0.980000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            " 100 101 102 103 104 105 106 107 108 109 135 136 137 138 139 155 156 157\n",
            " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199] [ 90  91  92  93  94  95  96  97  98  99 110 111 112 113 114 115 116 117\n",
            " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 140\n",
            " 141 142 143 144 145 146 147 148 149 150 151 152 153 154]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.95556, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint3_48\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.95556\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy improved from 0.95556 to 0.97778, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint3_48\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 102: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 103: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 104: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 105: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 106: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 107: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 108: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 109: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 110: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 111: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 112: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 113: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 114: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 115: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 116: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 117: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 118: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 119: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 120: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 121: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 122: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 123: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 124: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 125: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 126: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 127: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 128: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 129: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 130: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 131: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 132: val_out_activation_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 133: val_out_activation_accuracy did not improve from 0.97778\n",
            "Epoch 133: early stopping\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Fold 3 Classification accuracy: 0.960000 \n",
            "data:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 140 141 142 143 144 145 146 147 148\n",
            " 149 150 151 152 153 154] [135 136 137 138 139 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
            " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n",
            " 186 187 188 189 190 191 192 193 194 195 196 197 198 199]\n",
            "\n",
            "Epoch 1: val_out_activation_accuracy improved from -inf to 0.91111, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint4_48\n",
            "\n",
            "Epoch 2: val_out_activation_accuracy did not improve from 0.91111\n",
            "\n",
            "Epoch 3: val_out_activation_accuracy improved from 0.91111 to 0.93333, saving model to /content/drive/MyDrive/EEG_DATA/MTVAE_REGRESORxRuns/checkpoint4_48\n",
            "\n",
            "Epoch 4: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 5: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 6: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 7: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 8: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 9: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 10: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 11: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 12: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 13: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 14: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 15: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 16: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 17: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 18: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 19: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 20: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 21: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 22: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 23: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 24: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 25: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 26: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 27: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 28: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 29: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 30: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 31: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 32: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 33: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 34: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 35: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 36: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 37: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 38: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 39: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 40: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 41: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 42: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 43: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 44: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 45: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 46: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 47: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 48: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 49: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 50: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 51: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 52: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 53: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 54: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 55: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 56: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 57: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 58: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 59: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 60: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 61: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 62: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 63: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 64: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 65: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 66: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 67: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 68: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 69: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 70: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 71: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 72: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 73: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 74: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 75: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 76: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 77: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 78: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 79: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 80: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 81: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 82: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 83: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 84: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 85: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 86: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 87: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 88: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 89: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 90: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 91: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 92: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 93: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 94: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 95: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 96: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 97: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 98: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 99: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 100: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 101: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 102: val_out_activation_accuracy did not improve from 0.93333\n",
            "\n",
            "Epoch 103: val_out_activation_accuracy did not improve from 0.93333\n",
            "Epoch 103: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Fold 4 Classification accuracy: 1.000000 \n",
            "ACCURACY PER SUBJECT:  96.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ACC_MTVAE =          [89.0,66.5,98.0,90.0,99.0,84.0,72.0,79.5,77.5,90.5,73.5,75.5,96.5,98.0,83.5,76.5,78.5,78.0,80.5,75.0,63.5,82.0,95.5,78.0,87.0,96.5,78.5,90.0,81.0,78.0,79.0,79.0,70.5,85.5,78.0,87.0,66.5,80.0,77.5,96.0,79.5,94.0,95.0,75.0,83.0,96.0,100.0,76.5,78.5]"
      ],
      "metadata": {
        "id": "ev3mMv_tf4LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_mtvae_regresor = [89.0,74.5,98.0,87.0,98.5,84.5,85.0,84.0,85.0,92.5,81.5,88.5,93.0,96.5,86.0,88.0,83.5,79.5,84.5,85.0,71.5,86.5,90.0,83.0,87.0,97.5,88.5,86.0,82.5,78.0,83.0,75.5,78.0,82.5,81.0,88.0,74.5,82.0,87.5,94.0,87.5,94.5,94.0,84.0,88.5,96.0,98.0,86.0,86.4]"
      ],
      "metadata": {
        "id": "zzxfSngxoekb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "graficamos los resultados"
      ],
      "metadata": {
        "id": "5hfqba9FogW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar el ancho de las barras\n",
        "ancho_barra = 0.25\n",
        "\n",
        "# Calcular las posiciones para las barras\n",
        "posiciones_1 = np.arange(len(subjects))\n",
        "posiciones_2 = posiciones_1 + ancho_barra\n",
        "posiciones_3 = posiciones_2 + ancho_barra\n",
        "\n",
        "# Crear la figura y los ejes\n",
        "fig, ax = plt.subplots(figsize=(22, 8))\n",
        "\n",
        "# Dibujar -las barras\n",
        "ax.bar(posiciones_1, ACC_MTVAE, width=ancho_barra, label='MTVAE STANDAR')\n",
        "ax.bar(posiciones_3, acc_mtvae_regresor, width=ancho_barra, label='MTVAE REGRESOR ENCODER NO FREEZE')\n",
        "\n",
        "# Configurar el eje x\n",
        "ax.set_xticks(posiciones_2)\n",
        "ax.set_xticklabels(subjects)\n",
        "plt.legend()\n",
        "plt.title('MTVAE MODEL STANDAR VS REGRESOR')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "sUHCi6ZOoh3w",
        "outputId": "ad2e3a52-a6cd-4536-c8b7-67f967b00cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'MTVAE MODEL STANDAR VS REGRESOR')"
            ]
          },
          "metadata": {},
          "execution_count": 191
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### ORDENAMOS LA LISTA SEGUN LOS ACCURACY\n",
        "pares_ordenados = sorted(zip(ACC_MTVAE, subjects), reverse=True)\n",
        "pares_ordenados_2 = sorted(zip(ACC_MTVAE, acc_mtvae_regresor), reverse=True)\n",
        "acc_subj_MTVAE_ORDENADA, subjects_str_ORDENADA = zip(*pares_ordenados)\n",
        "acc_subj_MTVAE_ORDENADA, regresor_ORDENADA = zip(*pares_ordenados_2)"
      ],
      "metadata": {
        "id": "QxSsckKjv0JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar el ancho de las barras\n",
        "ancho_barra = 0.25\n",
        "\n",
        "# Calcular las posiciones para las barras\n",
        "posiciones_1 = np.arange(len(subjects_str_ORDENADA))\n",
        "posiciones_2 = posiciones_1 + ancho_barra\n",
        "posiciones_3 = posiciones_2 + ancho_barra\n",
        "\n",
        "# Crear la figura y los ejes\n",
        "fig, ax = plt.subplots(figsize=(22, 8))\n",
        "\n",
        "# Dibujar -las barras\n",
        "ax.bar(posiciones_1, acc_subj_MTVAE_ORDENADA, width=ancho_barra, label='MTVAE STANDAR')\n",
        "ax.bar(posiciones_3, regresor_ORDENADA , width=ancho_barra, label='MTVAE REGRESOR ENCODER NO FREEZE')\n",
        "\n",
        "# Configurar el eje x\n",
        "ax.set_xticks(posiciones_2)\n",
        "ax.set_xticklabels(subjects_str_ORDENADA)\n",
        "plt.legend()\n",
        "plt.title('MTVAE MODEL STANDAR VS REGRESOR')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "-dD99-Mnw7s0",
        "outputId": "a782b16c-46c5-442e-f8f1-dac99e184232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'MTVAE MODEL STANDAR VS REGRESOR')"
            ]
          },
          "metadata": {},
          "execution_count": 194
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}